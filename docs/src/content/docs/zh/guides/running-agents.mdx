---
title: 运行智能体
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';

智能体本身不会做任何事——您需要使用 `Runner` 类或 `run()` 工具来**运行**它们。

<Code lang="typescript" code={helloWorldExample} title="简单运行" />

当您不需要自定义 runner 时，也可以使用 `run()` 工具，它会运行一个单例的默认 `Runner` 实例。

或者，您可以创建自己的 `Runner` 实例：

<Code lang="typescript" code={helloWorldWithRunnerExample} title="简单运行" />

在运行完您的智能体后，您将收到一个 [Results](/openai-agents-js/zh/guides/results) 对象，其中包含最终输出和完整的运行历史。

## 智能体循环

当您在 Runner 中使用 run 方法时，您需要传入一个起始智能体和输入。输入可以是字符串（视为用户消息），也可以是输入项列表，这些输入项与 OpenAI Responses API 中的项目一致。

随后 Runner 会执行一个循环：

1. 使用当前输入调用当前智能体的模型。
2. 检查 LLM 响应。
   - **最终输出** → 返回。
   - **交接** → 切换到新智能体，保留累积的会话历史，回到 1。
   - **工具调用** → 执行工具，将其结果追加到会话中，回到 1。
3. 一旦达到 `maxTurns`，抛出 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror)。

<Aside type="note">
  判断 LLM
  输出是否为“最终输出”的规则是：它产出了具有期望类型的文本输出，且没有任何工具调用。
</Aside>

### Runner 生命周期

在应用启动时创建一个 `Runner` 并在请求之间复用。该实例会存储全局配置，例如模型提供方和追踪选项。只有在需要完全不同的设置时才创建另一个 `Runner`。对于简单脚本，您也可以直接调用 `run()`，它会在内部使用默认 runner。

## 运行参数

`run()` 方法的输入包括用于启动运行的初始智能体、此次运行的输入，以及一组选项。

输入可以是字符串（视为用户消息）、[input items](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) 列表，或者在构建[Human-in-the-loop](/openai-agents-js/zh/guides/human-in-the-loop) 智能体时使用的 [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) 对象。

附加选项包括：

| 选项       | 默认值  | 描述                                                                                                                   |
| ---------- | ------- | ---------------------------------------------------------------------------------------------------------------------- |
| `stream`   | `false` | 若为 `true`，调用将返回 `StreamedRunResult`，并在模型产生事件时逐步发出。                                              |
| `context`  | –       | 转发到每个工具 / 护栏 / 交接的上下文对象。详见[Context management](/openai-agents-js/zh/guides/context)。              |
| `maxTurns` | `10`    | 安全上限——达到后会抛出 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror)。 |
| `signal`   | –       | 用于取消的 `AbortSignal`。                                                                                             |

## 流式传输

流式传输允许您在 LLM 运行时额外接收流事件。一旦流开始，`StreamedRunResult` 将包含关于此次运行的完整信息，包括所有新产生的输出。您可以使用 `for await` 循环迭代这些流事件。更多内容请参阅[Streaming](/openai-agents-js/zh/guides/streaming)。

## 运行配置

如果您要创建自己的 `Runner` 实例，可以传入一个 `RunConfig` 对象来配置该 runner。

| 字段                        | 类型                  | 用途                                                     |
| --------------------------- | --------------------- | -------------------------------------------------------- |
| `model`                     | `string \| Model`     | 为运行中的**所有**智能体强制指定某个模型。               |
| `modelProvider`             | `ModelProvider`       | 解析模型名称——默认使用 OpenAI 提供方。                   |
| `modelSettings`             | `ModelSettings`       | 全局调参参数，会覆盖每个智能体的设置。                   |
| `handoffInputFilter`        | `HandoffInputFilter`  | 在执行交接时修改输入项（如果交接本身尚未定义的话）。     |
| `inputGuardrails`           | `InputGuardrail[]`    | 应用于*初始*用户输入的护栏。                             |
| `outputGuardrails`          | `OutputGuardrail[]`   | 应用于*最终*输出的护栏。                                 |
| `tracingDisabled`           | `boolean`             | 完全禁用 OpenAI 追踪。                                   |
| `traceIncludeSensitiveData` | `boolean`             | 将 LLM/工具的输入与输出从追踪中排除，同时仍然生成 span。 |
| `workflowName`              | `string`              | 显示在 Traces 仪表盘中——用于帮助对相关运行分组。         |
| `traceId` / `groupId`       | `string`              | 手动指定 trace 或 group ID，而不是让 SDK 自动生成。      |
| `traceMetadata`             | `Record<string, any>` | 附加到每个 span 的任意元数据。                           |

## 会话 / 聊天线程

每次调用 `runner.run()`（或 `run()` 工具）代表应用层会话中的一个**轮次**。您可以自行决定向终端用户展示多少 `RunResult` 内容——有时只展示 `finalOutput`，有时展示每一个生成的项目。

<Code lang="typescript" code={chatLoopExample} title="携带会话历史的示例" />

参见[聊天示例](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts)获取一个交互式版本。

## 异常

SDK 会抛出一小组可供捕获的错误：

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) – 达到 `maxTurns`。
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror) – 模型产生了无效输出（例如格式错误的 JSON、未知工具）。
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered) – 违反护栏。
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror) – 护栏执行失败。
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror) – 任一函数工具调用失败。
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror) – 基于配置或用户输入抛出的任意错误。

以上错误均继承自基础的 `AgentsError` 类，该类可能提供 `state` 属性用于访问当前运行状态。

下面是一个处理 `GuardrailExecutionError` 的代码示例：

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="护栏执行错误"
/>

运行上述示例时，您将看到如下输出：

```
Guardrail execution failed: Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework guardrail tripped
```

---

## 后续步骤

- 了解如何[Models](/openai-agents-js/zh/guides/models)。
- 为您的智能体提供[Tools](/openai-agents-js/zh/guides/tools)。
- 添加用于生产的[Guardrails](/openai-agents-js/zh/guides/guardrails)或[Tracing](/openai-agents-js/zh/guides/tracing)。
