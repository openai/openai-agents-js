---
title: 工具
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../../examples/docs/tools/mcpLocalServer.ts?raw';
import codexToolExample from '../../../../../../examples/docs/tools/codexTool.ts?raw';

工具让一个智能体能够**采取行动**——获取数据、调用外部 API、执行代码，甚至进行计算机操作。JavaScript/TypeScript SDK 支持六大类别：

1. **OpenAI 托管工具**——与模型一起在 OpenAI 服务器上运行。（Web 搜索、文件搜索、Code Interpreter、图像生成）
2. **本地内置工具**——在你的环境中运行。（计算机操作、shell、apply_patch）
3. **函数工具**——用 JSON schema 包装任何本地函数，让 LLM 可调用。
4. **Agents as tools**——将整个智能体暴露为可调用的工具。
5. **MCP servers**——挂载一个 Model Context Protocol 服务器（本地或远程）。
6. **实验性：Codex 工具**——将 Codex SDK 封装为函数工具，以运行感知工作区的任务。

---

## 1. 托管工具（OpenAI Responses API）

当你使用 `OpenAIResponsesModel` 时，可以添加以下内置工具：

| 工具             | 类型字符串           | 用途                             |
| ---------------- | -------------------- | -------------------------------- |
| Web 搜索         | `'web_search'`       | 互联网搜索。                     |
| 文件/检索搜索    | `'file_search'`      | 查询托管在 OpenAI 上的向量存储。 |
| Code Interpreter | `'code_interpreter'` | 在沙箱环境中运行代码。           |
| 图像生成         | `'image_generation'` | 基于文本生成图像。               |

<Code lang="typescript" code={toolsHostedToolsExample} title="托管工具" />

精确的参数集合与 OpenAI Responses API 一致——参阅官方文档以了解如 `rankingOptions` 或语义过滤等高级选项。

---

## 2. 本地内置工具

本地内置工具在你自己的环境中运行，并需要你提供实现：

- **计算机操作**——实现 `Computer` 接口并传入 `computerTool()`。
- **Shell**——实现 `Shell` 接口并传入 `shellTool()`。
- **应用补丁**——实现 `Editor` 接口并传入 `applyPatchTool()`。

这些工具在本地执行，**不**由 OpenAI 托管。当你需要在运行时直接访问文件、终端或 GUI 自动化时使用它们。工具调用仍由 OpenAI 模型的响应触发，但你的应用预期在本地执行它们。

<Code lang="typescript" code={localBuiltInToolsExample} title="本地内置工具" />

---

## 3. 函数工具

你可以使用 `tool()` 帮助函数将**任何**函数变成工具。

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="使用 Zod 参数的函数工具"
/>

### 选项参考

| 字段               | 必填 | 描述                                                                                                                                |
| ------------------ | ---- | ----------------------------------------------------------------------------------------------------------------------------------- |
| `name`             | 否   | 默认为函数名（例如 `get_weather`）。                                                                                                |
| `description`      | 是   | 面向人类、清晰的描述，展示给 LLM。                                                                                                  |
| `parameters`       | 是   | Zod schema 或原始 JSON schema 对象。使用 Zod 参数会自动启用**严格**模式。                                                           |
| `strict`           | 否   | 当为 `true`（默认）时，如果参数校验失败，SDK 会返回模型错误。设为 `false` 以启用模糊匹配。                                          |
| `execute`          | 是   | `(args, context) => string \| unknown \| Promise<...>`——你的业务逻辑。非字符串输出会被序列化给模型。可选第二个参数为 `RunContext`。 |
| `errorFunction`    | 否   | 自定义处理器 `(context, error) => string`，将内部错误转换为用户可见字符串。                                                         |
| `needsApproval`    | 否   | 在执行前需要人工批准。参见[人机协作](/openai-agents-js/zh/guides/human-in-the-loop)。                                               |
| `isEnabled`        | 否   | 按运行条件性地暴露工具；接受布尔值或谓词。                                                                                          |
| `inputGuardrails`  | 否   | 在工具执行前运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                          |
| `outputGuardrails` | 否   | 在工具执行后运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                          |

### 非严格 JSON Schema 工具

如果你需要模型在输入无效或不完整时进行“猜测”，可在使用原始 JSON schema 时禁用严格模式：

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="非严格 JSON schema 工具"
/>

---

## 4. Agents as tools

有时你希望一个智能体在不完全交接对话的情况下辅助另一个智能体。可使用 `agent.asTool()`：

<Code lang="typescript" code={agentsAsToolsExample} title="Agents as tools" />

在底层，SDK 会：

- 创建一个仅带 `input` 参数的函数工具。
- 当该工具被调用时，用该输入运行子智能体。
- 返回最后一条消息，或由 `customOutputExtractor` 提取的输出。

当你以工具的形式运行一个智能体时，Agents SDK 会使用默认设置创建一个 runner，并在函数执行中用它来运行该智能体。如果你想提供任何 `runConfig` 或 `runOptions` 的属性，可以将它们传递给 `asTool()` 方法以自定义 runner 的行为。

你也可以通过 `asTool()` 选项在智能体工具上设置 `needsApproval` 和 `isEnabled`，以集成人机协作流程和条件性工具可用性。

### 来自智能体工具的流式事件

智能体工具可以将所有嵌套的运行事件流式回传到你的应用。根据你构建工具的方式选择合适的钩子风格：

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="流式智能体工具"
/>

- 事件类型与 `RunStreamEvent['type']` 一致：`raw_model_stream_event`、`run_item_stream_event`、`agent_updated_stream_event`。
- `onStream` 是最简单的“全捕获”方式，适合在内联声明工具时使用（`tools: [agent.asTool({ onStream })]`）。当你不需要按事件路由时使用它。
- `on(eventName, handler)` 允许选择性订阅（或使用 `'*'`），适合需要更细粒度处理或在创建后附加监听器的场景。
- 如果提供了 `onStream` 或任一 `on(...)` 处理器，agent-as-tool 将自动以流式模式运行；否则保持非流式路径。
- 处理器并行调用，因此缓慢的 `onStream` 回调不会阻塞 `on(...)` 处理器（反之亦然）。
- 当工具通过模型工具调用触发时会提供 `toolCallId`；直接 `invoke()` 调用或部分供应商行为可能省略它。

---

## 5. MCP servers

你可以通过 [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) 服务器暴露工具，并将它们挂载到智能体上。
例如，你可以使用 `MCPServerStdio` 启动并连接到 stdio MCP 服务器：

<Code lang="typescript" code={mcpLocalServer} title="本地 MCP 服务器" />

完整示例参见 [`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts)。此外，如果你在寻找关于 MCP 服务器工具集成的完整指南，请参阅[MCP 集成](/openai-agents-js/zh/guides/mcp)获取详情。
在管理多个服务器（或部分失败）时，使用 `connectMcpServers` 并参考 [MCP 集成](/openai-agents-js/zh/guides/mcp#managing-mcp-server-lifecycle) 中的生命周期指南。

---

## 6. 实验性：Codex 工具

`@openai/agents-extensions/experimental/codex` 提供了 `codexTool()`，这是一个函数工具，将模型的工具调用路由到 Codex SDK，使智能体能够自主运行以工作区为作用域的任务（shell、文件编辑、MCP 工具）。该接口为实验性，可能会变更。

快速开始：

<Code lang="typescript" code={codexToolExample} title="实验性 Codex 工具" />

需要了解：

- 认证：提供 `CODEX_API_KEY`（首选）或 `OPENAI_API_KEY`，或传入 `codexOptions.apiKey`。
- 输入：严格的 schema——`inputs` 必须至少包含一个 `{ type: 'text', text }` 或 `{ type: 'local_image', path }`。
- 安全：将 `sandboxMode` 与 `workingDirectory` 搭配使用；如果目录不是 Git 仓库，设置 `skipGitRepoCheck`。
- 行为：`persistSession: true` 复用单个 Codex 线程并返回其 `threadId`；你可以将其暴露出来以便可恢复的工作。
- 流式传输：`onStream` 镜像 Codex 事件（推理、命令执行、MCP 工具调用、文件更改、Web 搜索），便于日志或追踪进度。
- 输出：工具结果包含 `response`、`usage` 和 `threadId`，且 Codex 的 token 用量会记录在 `RunContext` 中。
- 结构：当你需要类型化输出时，`outputSchema` 会在每轮强制结构化的 Codex 响应。

---

## 工具使用行为

参阅[智能体](/openai-agents-js/zh/guides/agents#forcing-tool-use)以控制模型何时以及如何必须使用工具（`tool_choice`、`toolUseBehavior` 等）。

---

## 最佳实践

- **简短且明确的描述**——描述工具做了什么以及何时使用它。
- **验证输入**——尽可能使用 Zod schema 进行严格的 JSON 校验。
- **避免在错误处理器中产生副作用**——`errorFunction` 应返回有用的字符串，不要抛出。
- **单一职责工具**——小而可组合的工具有助于更好的模型推理。

---

## 下一步

- 了解[强制工具使用](/openai-agents-js/zh/guides/agents#forcing-tool-use)。
- 添加[护栏](/openai-agents-js/zh/guides/guardrails)来验证工具输入或输出。
- 查阅 TypeDoc 参考文档了解 [`tool()`](/openai-agents-js/openai/agents/functions/tool) 及多种托管工具类型。
