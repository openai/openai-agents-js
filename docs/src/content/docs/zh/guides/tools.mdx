---
title: 工具
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../../examples/docs/tools/mcpLocalServer.ts?raw';
import codexToolExample from '../../../../../../examples/docs/tools/codexTool.ts?raw';

工具让智能体能够**采取行动**——获取数据、调用外部 API、执行代码，甚至使用计算机。JavaScript/TypeScript SDK 支持六种类别：

1. **OpenAI 托管工具**——与模型在 OpenAI 服务器上并行运行。（_Web 搜索、文件搜索、Code Interpreter、图像生成_）
2. **本地内置工具**——在您的环境中运行。（_计算机操作、shell、apply_patch_）
3. **函数工具**——用 JSON schema 包装任意本地函数，让 LLM 可以调用。
4. **将智能体作为工具**——将整个智能体暴露为可调用的工具。
5. **MCP 服务器**——挂载一个 Model Context Protocol 服务器（本地或远程）。
6. **实验性：Codex 工具**——将 Codex SDK 包装为函数工具以运行面向工作区的任务。

---

## 1. 托管工具（OpenAI Responses API）

当你使用 `OpenAIResponsesModel` 时，可以添加以下内置工具：

| 工具                    | 类型字符串           | 目的                             |
| ----------------------- | -------------------- | -------------------------------- |
| Web search              | `'web_search'`       | 互联网搜索。                     |
| File / retrieval search | `'file_search'`      | 查询托管在 OpenAI 上的向量存储。 |
| Code Interpreter        | `'code_interpreter'` | 在沙盒环境中运行代码。           |
| Image generation        | `'image_generation'` | 基于文本生成图像。               |

<Code lang="typescript" code={toolsHostedToolsExample} title="托管工具" />

具体参数集与 OpenAI Responses API 一致——高级选项如 `rankingOptions` 或语义过滤请参考官方文档。

---

## 2. 本地内置工具

本地内置工具在你自己的环境中运行，需要你提供实现：

- **计算机操作**——实现 `Computer` 接口并传给 `computerTool()`。
- **Shell**——实现 `Shell` 接口并传给 `shellTool()`。
- **Apply patch**——实现 `Editor` 接口并传给 `applyPatchTool()`。

这些工具在本地执行，**不**由 OpenAI 托管。当你需要在运行时直接访问文件、终端或 GUI 自动化时使用它们。工具调用仍由 OpenAI 模型的响应发起，但你的应用需要在本地执行。

<Code lang="typescript" code={localBuiltInToolsExample} title="本地内置工具" />

---

## 3. 函数工具

你可以用 `tool()` 帮助器把**任何**函数变成工具。

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="使用 Zod 参数的函数工具"
/>

### 选项参考

| 字段               | 必需 | 说明                                                                                                                                      |
| ------------------ | ---- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| `name`             | 否   | 默认为函数名（例如，`get_weather`）。                                                                                                     |
| `description`      | 是   | 提供给 LLM 的清晰、可读的人类描述。                                                                                                       |
| `parameters`       | 是   | Zod schema 或原始 JSON schema 对象。使用 Zod 参数会自动启用 **strict** 模式。                                                             |
| `strict`           | 否   | 当为 `true`（默认）时，如果参数校验失败，SDK 返回模型错误。将其设为 `false` 以启用模糊匹配。                                              |
| `execute`          | 是   | `(args, context) => string \| unknown \| Promise<...>`——你的业务逻辑。非字符串输出会被序列化供模型使用。可选的第二个参数为 `RunContext`。 |
| `errorFunction`    | 否   | 自定义处理器 `(context, error) => string`，将内部错误转换为用户可见的字符串。                                                             |
| `needsApproval`    | 否   | 执行前需要人工批准。参见[人机协作](/openai-agents-js/zh/guides/human-in-the-loop)。                                                       |
| `isEnabled`        | 否   | 按运行时条件暴露工具；接受布尔值或谓词。                                                                                                  |
| `inputGuardrails`  | 否   | 在工具执行前运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                |
| `outputGuardrails` | 否   | 在工具执行后运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                |

### 非严格 JSON schema 工具

如果你需要模型在输入无效或不完整时进行“猜测”，可以在使用原始 JSON schema 时禁用严格模式：

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="非严格 JSON schema 工具"
/>

---

## 4. 将智能体作为工具

有时你希望一个智能体在不完全交接会话的情况下“协助”另一个智能体。使用 `agent.asTool()`：

<Code lang="typescript" code={agentsAsToolsExample} title="将智能体作为工具" />

在底层，SDK 会：

- 创建一个只有 `input` 参数的函数工具。
- 在工具被调用时，用该输入运行子智能体。
- 返回最后一条消息或由 `customOutputExtractor` 提取的输出。

当你将智能体作为工具运行时，Agents SDK 会用默认设置创建一个 runner，并在函数执行中用它运行该智能体。如果你想提供任何 `runConfig` 或 `runOptions` 的属性，可以将它们传给 `asTool()` 方法以自定义 runner 的行为。

你也可以通过 `asTool()` 选项在智能体工具上设置 `needsApproval` 和 `isEnabled`，以集成人机协作流程和条件性工具可用性。

### 来自智能体工具的流式事件

智能体工具可以将所有嵌套运行事件流式传回你的应用。选择适合你构造工具方式的钩子样式：

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="流式智能体工具"
/>

- 事件类型与 `RunStreamEvent['type']` 一致：`raw_model_stream_event`、`run_item_stream_event`、`agent_updated_stream_event`。
- `onStream` 是最简单的“全捕获”，适合内联声明工具（`tools: [agent.asTool({ onStream })]`）。若不需要按事件路由，请使用它。
- `on(eventName, handler)` 允许选择性订阅（或使用 `'*'`），当你需要更细粒度的处理或在创建后附加监听器时最佳。
- 如果提供了 `onStream` 或任意 `on(...)` 处理器，智能体作为工具将自动以流式模式运行；否则保持非流式路径。
- 处理器并行调用，因此较慢的 `onStream` 回调不会阻塞 `on(...)` 处理器（反之亦然）。
- 当工具通过模型的工具调用触发时会提供 `toolCallId`；直接 `invoke()` 调用或某些提供方行为可能省略它。

---

## 5. MCP 服务器

你可以通过[Model Context Protocol (MCP)](https://modelcontextprotocol.io/) 服务器暴露工具，并将其挂载到智能体。
例如，你可以使用 `MCPServerStdio` 启动并连接到 stdio MCP 服务器：

<Code lang="typescript" code={mcpLocalServer} title="本地 MCP 服务器" />

完整示例见 [`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts)。另外，如果你在寻找关于 MCP 服务器工具集成的综合指南，请参阅[MCP 集成](/openai-agents-js/zh/guides/mcp)了解详情。

---

## 6. 实验性：Codex 工具

`@openai/agents-extensions/experimental/codex` 提供 `codexTool()`，这是一个函数工具，可将模型的工具调用路由到 Codex SDK，从而让智能体自主运行以工作区为范围的任务（shell、文件编辑、MCP 工具）。该接口为实验性，可能会变更。

快速开始：

<Code lang="typescript" code={codexToolExample} title="实验性 Codex 工具" />

须知事项：

- 认证：提供 `CODEX_API_KEY`（优先）或 `OPENAI_API_KEY`，或传入 `codexOptions.apiKey`。
- 输入：严格的 schema——`inputs` 必须至少包含一个 `{ type: 'text', text }` 或 `{ type: 'local_image', path }`。
- 安全：将 `sandboxMode` 与 `workingDirectory` 搭配使用；如果目录不是 Git 仓库，请设置 `skipGitRepoCheck`。
- 行为：`persistSession: true` 复用单个 Codex 线程并返回其 `threadId`；你可以将其暴露以便恢复工作。
- 流式传输：`onStream` 映射 Codex 事件（推理、命令执行、MCP 工具调用、文件变更、Web 搜索），以便记录或追踪进度。
- 输出：工具结果包含 `response`、`usage` 和 `threadId`，Codex 的 token 用量记录在 `RunContext` 中。
- 结构：当你需要类型化输出时，`outputSchema` 会在每一轮强制 Codex 返回结构化响应。

---

## 工具使用行为

关于控制模型何时以及如何必须使用工具（`tool_choice`、`toolUseBehavior` 等），请参见[智能体](/openai-agents-js/zh/guides/agents#forcing-tool-use)。

---

## 最佳实践

- **简短且明确的描述**——说明工具做了什么、何时使用它。
- **校验输入**——尽可能使用 Zod schema 进行严格的 JSON 校验。
- **避免在错误处理器中产生副作用**——`errorFunction` 应返回有用的字符串，而不是抛出异常。
- **单一职责原则**——小而可组合的工具有助于更好的模型推理。

---

## 后续步骤

- 了解[强制使用工具](/openai-agents-js/zh/guides/agents#forcing-tool-use)。
- 添加[护栏](/openai-agents-js/zh/guides/guardrails)以校验工具输入或输出。
- 查阅 TypeDoc 参考文档：[`tool()`](/openai-agents-js/openai/agents/functions/tool) 以及各类托管工具类型。
