---
title: 工具
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../../examples/docs/tools/mcpLocalServer.ts?raw';
import codexToolExample from '../../../../../../examples/docs/tools/codexTool.ts?raw';

工具让智能体**执行操作**——获取数据、调用外部 API、执行代码，甚至进行计算机操作。JavaScript/TypeScript SDK 支持六种类别：

1. **OpenAI 托管工具**——在 OpenAI 服务器上与模型并行运行。（Web 搜索、文件搜索、Code Interpreter、图像生成）
2. **本地内置工具**——在您的环境中运行。（计算机操作、shell、apply_patch）
3. **函数工具**——用 JSON schema 包装任意本地函数，以便 LLM 可以调用。
4. **Agents as tools**——将整个智能体暴露为可调用的工具。
5. **MCP 服务器**——挂载一个 Model Context Protocol 服务器（本地或远程）。
6. **实验性：Codex 工具**——将 Codex SDK 包装为函数工具以运行感知工作区的任务。

---

## 1. 托管工具（OpenAI Responses API）

当您使用 `OpenAIResponsesModel` 时，可以添加以下内置工具：

| Tool                    | Type string          | Purpose                          |
| ----------------------- | -------------------- | -------------------------------- |
| Web search              | `'web_search'`       | 互联网搜索。                     |
| File / retrieval search | `'file_search'`      | 查询托管在 OpenAI 上的向量存储。 |
| Code Interpreter        | `'code_interpreter'` | 在沙箱环境中运行代码。           |
| Image generation        | `'image_generation'` | 基于文本生成图像。               |

<Code lang="typescript" code={toolsHostedToolsExample} title="托管工具" />

具体参数集与 OpenAI Responses API 完全一致——高级选项（如 `rankingOptions` 或语义过滤器）请参考官方文档。

---

## 2. 本地内置工具

本地内置工具在您的环境中运行，需要您提供实现：

- **计算机操作**——实现 `Computer` 接口并传入 `computerTool()`。
- **Shell**——实现 `Shell` 接口并传入 `shellTool()`。
- **应用补丁**——实现 `Editor` 接口并传入 `applyPatchTool()`。

这些工具在本地执行，**不**由 OpenAI 托管。需要在运行时直接访问文件、终端或 GUI 自动化时使用它们。工具调用仍由 OpenAI 模型的响应请求，但您的应用需在本地执行。

<Code lang="typescript" code={localBuiltInToolsExample} title="本地内置工具" />

---

## 3. 函数工具

您可以使用 `tool()` 辅助函数将**任意**函数变为工具。

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="使用 Zod 参数的函数工具"
/>

### 选项参考

| Field              | Required | Description                                                                                                                               |
| ------------------ | -------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| `name`             | No       | 默认为函数名（例如 `get_weather`）。                                                                                                      |
| `description`      | Yes      | 清晰、可读的人类描述，供 LLM 参考。                                                                                                       |
| `parameters`       | Yes      | 可以是 Zod schema 或原始 JSON schema 对象。使用 Zod 参数会自动启用 **strict** 模式。                                                      |
| `strict`           | No       | 当为 `true`（默认）时，如果参数验证失败，SDK 将返回模型错误。设置为 `false` 可进行模糊匹配。                                              |
| `execute`          | Yes      | `(args, context) => string \| unknown \| Promise<...>` —— 您的业务逻辑。非字符串输出会被序列化返回给模型。可选第二个参数为 `RunContext`。 |
| `errorFunction`    | No       | 自定义处理器 `(context, error) => string`，用于将内部错误转换为用户可见的字符串。                                                         |
| `needsApproval`    | No       | 在执行前需要人工批准。参见[人机协作](/openai-agents-js/zh/guides/human-in-the-loop)。                                                     |
| `isEnabled`        | No       | 按运行条件性地暴露该工具；接受布尔值或谓词。                                                                                              |
| `inputGuardrails`  | No       | 在工具执行前运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                |
| `outputGuardrails` | No       | 在工具执行后运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                |

### 非严格 JSON‑schema 工具

如果需要模型在输入无效或不完整时进行“猜测”，使用原始 JSON schema 时可以关闭严格模式：

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="非严格 JSON schema 工具"
/>

---

## 4. Agents as tools

有时您希望一个智能体在不完全交接对话的情况下“协助”另一个智能体。使用 `agent.asTool()`：

<Code lang="typescript" code={agentsAsToolsExample} title="Agents as tools" />

在底层，SDK 会：

- 创建一个仅包含 `input` 参数的函数工具。
- 在调用该工具时，用该输入运行子智能体。
- 返回最后一条消息或由 `customOutputExtractor` 提取的输出。

当您将智能体作为工具运行时，Agents SDK 会使用默认设置创建一个 runner，并在函数执行中用它来运行该智能体。如果希望提供任何 `runConfig` 或 `runOptions` 的属性，可以将它们传给 `asTool()` 以自定义 runner 的行为。

您也可以通过 `asTool()` 选项在智能体工具上设置 `needsApproval` 和 `isEnabled`，以集成人机协作流程和条件性工具可用性。

`agent.asTool()` 的高级结构化输入选项：

- `inputBuilder`：将结构化工具参数映射到嵌套智能体的输入负载。
- `includeInputSchema`：在嵌套运行中包含输入 JSON schema，以获得更强的 schema 感知行为。
- `resumeState`：在恢复嵌套序列化的 `RunState` 时控制上下文对齐策略。

### 来自智能体工具的流式事件

智能体工具可以将所有嵌套运行事件流式传回到您的应用。根据您构建工具的方式选择合适的钩子风格：

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="流式传输的智能体工具"
/>

- 事件类型与 `RunStreamEvent['type']` 一致：`raw_model_stream_event`、`run_item_stream_event`、`agent_updated_stream_event`。
- `onStream` 是最简单的“全捕获”，适合在内联声明工具时使用（`tools: [agent.asTool({ onStream })]`）。如果不需要按事件路由，使用它即可。
- `on(eventName, handler)` 允许您选择性订阅（或使用 `'*'`），更适合需要更细粒度处理或在创建后附加监听器的场景。
- 如果提供了 `onStream` 或任一 `on(...)` 处理器，作为工具的智能体将自动以流式模式运行；否则保持非流式路径。
- 处理器并行调用，因此缓慢的 `onStream` 回调不会阻塞 `on(...)` 处理器（反之亦然）。
- 当工具通过模型工具调用触发时会提供 `toolCallId`；直接 `invoke()` 调用或某些提供方特性可能省略它。

---

## 5. MCP 服务器

您可以通过[Model Context Protocol (MCP)](https://modelcontextprotocol.io/) 服务器暴露工具，并将其挂载到智能体上。
例如，可以使用 `MCPServerStdio` 启动并连接到 stdio MCP 服务器：

<Code lang="typescript" code={mcpLocalServer} title="本地 MCP 服务器" />

完整示例请参阅[`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts)。此外，如果您在寻找有关 MCP 服务器工具集成的完整指南，请参见[MCP 集成](/openai-agents-js/zh/guides/mcp)了解详情。
在管理多个服务器（或部分失败）时，请使用 `connectMcpServers` 并参考[MCP 集成](/openai-agents-js/zh/guides/mcp#managing-mcp-server-lifecycle)中的生命周期指引。

---

## 6. 实验性：Codex 工具

`@openai/agents-extensions/experimental/codex` 提供 `codexTool()`，这是一个函数工具，将模型的工具调用路由到 Codex SDK，使智能体可以自主运行以工作区为范围的任务（shell、文件编辑、MCP 工具）。该接口为实验性，可能发生变更。

快速开始：

<Code lang="typescript" code={codexToolExample} title="实验性的 Codex 工具" />

须知：

- 认证：提供 `CODEX_API_KEY`（首选）或 `OPENAI_API_KEY`，或传入 `codexOptions.apiKey`。
- 输入：严格的 schema——`inputs` 至少包含一个 `{ type: 'text', text }` 或 `{ type: 'local_image', path }`。
- 安全：将 `sandboxMode` 与 `workingDirectory` 搭配使用；如果目录不是 Git 仓库，则设置 `skipGitRepoCheck`。
- 行为：`persistSession: true` 复用单个 Codex 线程并返回其 `threadId`；您可以将其暴露以便恢复式工作。
- 流式传输：`onStream` 映射 Codex 事件（推理、命令执行、MCP 工具调用、文件更改、Web 搜索），以便记录或追踪进度。
- 输出：工具结果包含 `response`、`usage` 和 `threadId`，Codex 的 token 使用量会记录在 `RunContext` 中。
- 结构：`outputSchema` 可在需要类型化输出时，按回合强制结构化 Codex 响应。

---

## 工具使用行为

关于控制模型何时以及如何必须使用工具（`modelSettings.toolChoice`、`toolUseBehavior` 等），请参见[智能体](/openai-agents-js/zh/guides/agents#forcing-tool-use)。

---

## 最佳实践

- **简短、明确的描述**——描述工具做什么以及何时使用它。
- **验证输入**——尽可能使用 Zod schema 进行严格的 JSON 验证。
- **避免在错误处理器中产生副作用**——`errorFunction` 应返回有用的字符串，而非抛出异常。
- **单一职责的工具**——小而可组合的工具有助于更好的模型推理。

---

## 下一步

- 了解[强制使用工具](/openai-agents-js/zh/guides/agents#forcing-tool-use)。
- 添加[护栏](/openai-agents-js/zh/guides/guardrails)以验证工具输入或输出。
- 查阅 TypeDoc 参考：[`tool()`](/openai-agents-js/openai/agents/functions/tool) 以及各类托管工具类型。
