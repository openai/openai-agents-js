---
title: MCP 集成
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import hostedConnectorExample from '../../../../../../examples/docs/mcp/hostedConnector.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';
import toolFilterExample from '../../../../../../examples/docs/mcp/tool-filter.ts?raw';

[**Model Context Protocol (MCP)**](https://modelcontextprotocol.io) 是一种开放协议，用于标准化应用如何向 LLM 提供工具与上下文。摘自 MCP 文档：

> MCP 是一种开放协议，用于标准化应用如何向 LLM 提供上下文。可以把 MCP 看作 AI 应用的 USB‑C 接口。正如 USB‑C 为你的设备连接各种外设与配件提供标准化方式，MCP 为 AI 模型连接不同数据源与工具提供了标准化方式。

本 SDK 支持三种 MCP 服务器类型：

1. **托管 MCP 服务器工具**——由 [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp) 作为工具使用的远程 MCP 服务器
2. **Streamable HTTP MCP 服务器**——实现了 [Streamable HTTP 传输](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http) 的本地或远程服务器
3. **Stdio MCP 服务器**——通过标准输入/输出访问的服务器（最简单的选项）

> 注意：SDK 还包含用于传统 Server‑Sent Events 传输的 `MCPServerSSE`，但 SSE 已被 MCP 项目弃用。新集成请优先选择 Streamable HTTP 或 stdio。

请根据你的使用场景选择服务器类型：

| 你的需求                                                    | 推荐选项               |
| ----------------------------------------------------------- | ---------------------- |
| 使用默认的 OpenAI responses 模型调用可公开访问的远程服务器  | **1. 托管 MCP 工具**   |
| 使用可公开访问的远程服务器，但在本地触发工具调用            | **2. Streamable HTTP** |
| 使用本地运行的 Streamable HTTP 服务器                       | **2. Streamable HTTP** |
| 在非 OpenAI‑Responses 模型中使用任意 Streamable HTTP 服务器 | **2. Streamable HTTP** |
| 使用仅支持标准 I/O 协议的本地 MCP 服务器                    | **3. Stdio**           |

## 1. 托管 MCP 服务器工具

托管工具将整个往返交互推入模型内部。你的代码无需调用 MCP 服务器，OpenAI Responses API 会调用远程工具端点并将结果流式回传给模型。

以下是使用托管 MCP 工具的最简示例。你可以将远程 MCP 服务器的标签与 URL 传给 `hostedMcpTool` 工具函数，便于创建托管 MCP 服务器工具。

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

随后，你可以使用 `run` 函数（或你自定义的 `Runner` 实例的 `run` 方法）来运行智能体：

<Code lang="typescript" code={hostedExample} title="使用托管 MCP 工具运行" />

如需流式获取增量 MCP 结果，在运行 `Agent` 时传入 `stream: true`：

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="使用托管 MCP 工具运行（流式传输）"
/>

#### 可选的审批流程

对于敏感操作，你可以要求对单次工具调用进行人工审批。可传入 `requireApproval: 'always'`，或传入一个将工具名称映射为 `'never'`/`'always'` 的细粒度对象。

如果你能以编程方式判断工具调用是否安全，可使用 [`onApproval` 回调](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts)来批准或拒绝工具调用。如果你需要人工审批，可使用与本地函数工具相同的基于 `interruptions` 的[人机协作（HITL）方法](/openai-agents-js/zh/guides/human-in-the-loop/)。

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="托管 MCP 工具的人机协作"
/>

### 连接器支持的托管服务器

托管 MCP 也支持 OpenAI 连接器。无需提供 `serverUrl`，改为传入连接器的 `connectorId` 与 `authorization` 令牌。Responses API 随后会处理认证，并通过托管 MCP 接口暴露连接器的工具。

<Code
  lang="typescript"
  code={hostedConnectorExample}
  title="由连接器支持的托管 MCP 工具"
/>

在此示例中，环境变量 `GOOGLE_CALENDAR_AUTHORIZATION` 保存了从 Google OAuth Playground 获取的 OAuth 令牌，授权由连接器支持的服务器调用 Calendar API。有关同时演示流式传输的可运行示例，请参阅 [`examples/connectors`](https://github.com/openai/openai-agents-js/tree/main/examples/connectors)。

完整可运行示例（托管工具/Streamable HTTP/stdio + 流式传输、HITL、onApproval）请见我们 GitHub 仓库中的 [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp)。

## 2. Streamable HTTP MCP 服务器

当你的智能体直接与本地或远程的 Streamable HTTP MCP 服务器对话时，请使用服务器的 `url`、`name` 以及可选设置来实例化 `MCPServerStreamableHttp`：

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="使用 Streamable HTTP MCP 服务器运行"
/>

该构造函数还接受其他 MCP TypeScript‑SDK 选项，如 `authProvider`、`requestInit`、`fetch`、`reconnectionOptions` 和 `sessionId`。详情参见 [MCP TypeScript SDK 仓库](https://github.com/modelcontextprotocol/typescript-sdk)及其文档。

## 3. Stdio MCP 服务器

对于仅暴露标准 I/O 的服务器，使用 `fullCommand` 来实例化 `MCPServerStdio`：

<Code lang="typescript" code={stdioExample} title="使用 Stdio MCP 服务器运行" />

## 其他须知

对于 **Streamable HTTP** 与 **Stdio** 服务器，每次运行 `Agent` 时都可能调用 `list_tools()` 来发现可用工具。由于该往返会带来延迟——尤其是对远程服务器——你可以通过向 `MCPServerStdio` 或 `MCPServerStreamableHttp` 传入 `cacheToolsList: true` 来将结果缓存在内存中。

仅当你确信工具列表不会变化时才启用此选项。若需稍后使缓存失效，可在服务器实例上调用 `invalidateToolsCache()`。

### 工具过滤

你可以通过 `createMCPToolStaticFilter` 提供静态过滤器，或传入自定义函数，来限制每个服务器暴露的工具。下面是一个结合两种方式的示例：

<Code lang="typescript" code={toolFilterExample} title="工具过滤" />

## 延伸阅读

- [Model Context Protocol](https://modelcontextprotocol.io/)——官方规范。
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp)——上文提及的可运行演示。
