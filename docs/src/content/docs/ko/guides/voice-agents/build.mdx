---
title: 음성 에이전트 구축
description: Learn how to build voice agents using the OpenAI Agents SDK, what features are available, how to architecture your application, and more.
---

import { Steps, Aside, Code } from '@astrojs/starlight/components';
import createAgentExample from '../../../../../../../examples/docs/voice-agents/createAgent.ts?raw';
import multiAgentsExample from '../../../../../../../examples/docs/voice-agents/multiAgents.ts?raw';
import createSessionExample from '../../../../../../../examples/docs/voice-agents/createSession.ts?raw';
import configureSessionExample from '../../../../../../../examples/docs/voice-agents/configureSession.ts?raw';
import handleAudioExample from '../../../../../../../examples/docs/voice-agents/handleAudio.ts?raw';
import defineToolExample from '../../../../../../../examples/docs/voice-agents/defineTool.ts?raw';
import toolApprovalEventExample from '../../../../../../../examples/docs/voice-agents/toolApprovalEvent.ts?raw';
import guardrailsExample from '../../../../../../../examples/docs/voice-agents/guardrails.ts?raw';
import guardrailSettingsExample from '../../../../../../../examples/docs/voice-agents/guardrailSettings.ts?raw';
import audioInterruptedExample from '../../../../../../../examples/docs/voice-agents/audioInterrupted.ts?raw';
import sessionInterruptExample from '../../../../../../../examples/docs/voice-agents/sessionInterrupt.ts?raw';
import sessionHistoryExample from '../../../../../../../examples/docs/voice-agents/sessionHistory.ts?raw';
import historyUpdatedExample from '../../../../../../../examples/docs/voice-agents/historyUpdated.ts?raw';
import updateHistoryExample from '../../../../../../../examples/docs/voice-agents/updateHistory.ts?raw';
import customWebRTCTransportExample from '../../../../../../../examples/docs/voice-agents/customWebRTCTransport.ts?raw';
import websocketSessionExample from '../../../../../../../examples/docs/voice-agents/websocketSession.ts?raw';
import transportEventsExample from '../../../../../../../examples/docs/voice-agents/transportEvents.ts?raw';
import thinClientExample from '../../../../../../../examples/docs/voice-agents/thinClient.ts?raw';
import toolHistoryExample from '../../../../../../../examples/docs/voice-agents/toolHistory.ts?raw';
import sendMessageExample from '../../../../../../../examples/docs/voice-agents/sendMessage.ts?raw';
import serverAgentExample from '../../../../../../../examples/docs/voice-agents/serverAgent.ts?raw';
import delegationAgentExample from '../../../../../../../examples/docs/voice-agents/delegationAgent.ts?raw';
import turnDetectionExample from '../../../../../../../examples/docs/voice-agents/turnDetection.ts?raw';

## 오디오 처리

기본 `OpenAIRealtimeWebRTC`와 같은 일부 전송 계층은 오디오 입력과 출력을 자동으로 처리합니다. `OpenAIRealtimeWebSocket` 같은 다른 전송 방식의 경우에는 세션 오디오를 직접 처리해야 합니다:

<Code lang="typescript" code={handleAudioExample} />

## 세션 구성

[`RealtimeSession`](/openai-agents-js/openai/agents-realtime/classes/realtimesession/) 생성 시 또는 `connect(...)` 호출 시 추가 옵션을 전달하여 세션을 구성할 수 있습니다.

<Code lang="typescript" code={configureSessionExample} />

이 전송 계층들은 [session](https://platform.openai.com/docs/api-reference/realtime-client-events/session/update)과 일치하는 모든 매개변수를 전달할 수 있습니다.

[RealtimeSessionConfig](/openai-agents-js/openai/agents-realtime/type-aliases/realtimesessionconfig/)에 아직 대응 항목이 없는 새로운 매개변수의 경우 `providerData`를 사용할 수 있습니다. `providerData`로 전달된 값은 `session` 객체의 일부로 그대로 전달됩니다.

생성 시 설정할 수 있는 추가 `RealtimeSession` 옵션:

| Option                                        | Type                              | Purpose                                                        |
| --------------------------------------------- | --------------------------------- | -------------------------------------------------------------- |
| `context`                                     | `TContext`                        | 세션 컨텍스트에 병합될 추가 로컬 컨텍스트                      |
| `historyStoreAudio`                           | `boolean`                         | 로컬 히스토리 스냅샷에 오디오 데이터를 저장 (기본값: 비활성화) |
| `outputGuardrails`                            | `RealtimeOutputGuardrail[]`       | 세션의 출력 가드레일 (참고: [가드레일](#guardrails))           |
| `outputGuardrailSettings`                     | `RealtimeOutputGuardrailSettings` | 가드레일 검사 빈도와 동작                                      |
| `tracingDisabled`                             | `boolean`                         | 세션에 대한 트레이싱 비활성화                                  |
| `groupId`                                     | `string`                          | 세션 또는 백엔드 실행 전반에 걸쳐 트레이스를 그룹화            |
| `traceMetadata`                               | `Record<string, any>`             | 세션 트레이스에 첨부할 사용자 지정 메타데이터                  |
| `workflowName`                                | `string`                          | 트레이스 워크플로의 표시 이름                                  |
| `automaticallyTriggerResponseForMcpToolCalls` | `boolean`                         | MCP 도구 호출 완료 시 모델 응답 자동 트리거 (기본값: `true`)   |
| `toolErrorFormatter`                          | `ToolErrorFormatter`              | 모델에 반환되는 도구 승인 거부 메시지 커스터마이즈             |

`connect(...)` 옵션:

| Option   | Type                                          | Purpose                                    |
| -------- | --------------------------------------------- | ------------------------------------------ |
| `apiKey` | `string \| (() => string \| Promise<string>)` | 이 연결에 사용되는 API 키(또는 지연 로더)  |
| `model`  | `OpenAIRealtimeModels \| string`              | 전송 연결에 대한 선택적 모델 재정의        |
| `url`    | `string`                                      | 선택적 사용자 지정 Realtime 엔드포인트 URL |
| `callId` | `string`                                      | 기존 SIP로 시작된 통화/세션에 연결         |

## 핸드오프

일반 에이전트와 마찬가지로, 핸드오프를 사용해 에이전트를 여러 에이전트로 분할하고 그 사이를 오케스트레이션하여 성능을 개선하고 문제 범위를 더 적절히 한정할 수 있습니다.

<Code lang="typescript" code={multiAgentsExample} />

일반 에이전트와 달리, 실시간 에이전트에서는 핸드오프 동작이 약간 다릅니다. 핸드오프가 수행되면 진행 중인 세션이 새로운 에이전트 구성으로 업데이트됩니다. 이로 인해 에이전트는 자동으로 진행 중인 대화 기록에 접근할 수 있으며 입력 필터는 현재 적용되지 않습니다.

또한, 핸드오프의 일부로 `voice` 또는 `model`은 변경할 수 없습니다. 다른 실시간 에이전트에만 연결할 수 있습니다. 예를 들어 `gpt-5-mini` 같은 추론 모델 등 다른 모델을 사용해야 하는 경우 [도구를 통한 위임](#delegation-through-tools)을 사용할 수 있습니다.

## 도구

일반 에이전트와 마찬가지로, 실시간 에이전트도 동작을 수행하기 위해 도구를 호출할 수 있습니다. Realtime은 **함수 도구**(로컬에서 실행)와 **호스티드 MCP 도구**(Realtime API가 원격으로 실행)를 지원합니다. 일반 에이전트에서 사용하는 것과 동일한 `tool()` 헬퍼로 함수 도구를 정의할 수 있습니다.

<Code lang="typescript" code={defineToolExample} />

함수 도구는 `RealtimeSession`과 동일한 환경에서 실행됩니다. 즉, 세션을 브라우저에서 실행 중이라면 도구도 브라우저에서 실행됩니다. 민감한 작업을 수행해야 한다면 도구 내부에서 백엔드로 HTTP 요청을 보내세요.

호스티드 MCP 도구는 `hostedMcpTool`로 구성하고 원격에서 실행됩니다. MCP 도구 가용성이 변경되면 세션은 `mcp_tools_changed`를 발생시킵니다. MCP 도구 호출 완료 후 세션이 자동으로 모델 응답을 트리거하지 않게 하려면 `automaticallyTriggerResponseForMcpToolCalls: false`로 설정하세요.

도구가 실행되는 동안 에이전트는 사용자의 새 요청을 처리할 수 없습니다. 경험을 개선하는 한 가지 방법은 에이전트에게 도구를 실행하려고 할 때 이를 알리거나, 도구를 실행할 시간을 벌기 위해 특정 문구를 말하도록 지시하는 것입니다.

함수 도구가 즉시 다른 모델 응답을 트리거하지 않고 종료되어야 한다면, `@openai/agents/realtime`의 `backgroundResult(output)`를 반환하세요.
이렇게 하면 응답 트리거는 그대로 두고 도구 출력을 세션으로 다시 전송합니다.

함수 도구 타임아웃 옵션(`timeoutMs`, `timeoutBehavior`, `timeoutErrorFunction`)은 Realtime 세션에서도 동일하게 동작합니다. 기본값 `error_as_result`인 경우, 타임아웃 메시지가 도구 출력으로 전송됩니다. `raise_exception`인 경우, 세션이 [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror)와 함께 `error` 이벤트를 발생시키며 해당 호출에 대한 도구 출력을 전송하지 않습니다.

### 대화 기록 접근

에이전트가 특정 도구를 호출할 때 전달된 인자 외에도, Realtime 세션이 추적하는 현재 대화 기록의 스냅샷에 접근할 수 있습니다. 이는 현재 대화 상태에 기반해 더 복잡한 작업을 수행해야 하거나 [도구를 통한 위임](#delegation-through-tools)을 사용할 계획이 있을 때 유용합니다.

<Code lang="typescript" code={toolHistoryExample} />

<Aside type="note">
  전달되는 히스토리는 도구 호출 시점의 히스토리 스냅샷입니다. 사용자가
  마지막으로 말한 내용의 전사가 아직 제공되지 않았을 수 있습니다.
</Aside>

### 도구 실행 전 승인

도구를 `needsApproval: true`로 정의하면, 에이전트가 도구를 실행하기 전에 `tool_approval_requested` 이벤트를 발생시킵니다.

이 이벤트를 수신하여 도구 호출을 승인하거나 거부하도록 사용자에게 UI를 표시할 수 있습니다.

<Code lang="typescript" code={toolApprovalEventExample} />

<Aside type="note">
  음성 에이전트가 도구 호출 승인을 기다리는 동안에는 사용자의 새 요청을 처리할
  수 없습니다.
</Aside>

## 가드레일

가드레일은 에이전트의 발화가 특정 규칙을 위반했는지 모니터링하고 즉시 응답을 차단할 수 있는 기능을 제공합니다. 이러한 가드레일 검사는 에이전트 응답의 전사(transcript)에 기반해 수행되므로, 모델의 텍스트 출력이 활성화되어 있어야 합니다(기본 활성화).

제공한 가드레일은 모델 응답이 반환되는 동안 비동기적으로 실행되며, 예를 들어 "특정 금지어를 언급"과 같은 사전 정의된 분류 트리거에 따라 응답을 차단할 수 있습니다.

가드레일이 발동하면 세션은 `guardrail_tripped` 이벤트를 발생시킵니다. 이벤트는 또한 가드레일을 트리거한 `itemId`를 포함하는 `details` 객체를 제공합니다.

<Code lang="typescript" code={guardrailsExample} />

기본적으로 가드레일은 100자마다 또는 응답 텍스트 생성이 끝날 때 실행됩니다.
텍스트를 음성으로 출력하는 데는 보통 더 오래 걸리므로, 대부분의 경우 사용자가 듣기 전에
가드레일이 위반을 포착할 수 있습니다.

이 동작을 변경하려면 세션에 `outputGuardrailSettings` 객체를 전달하세요.

<Code lang="typescript" code={guardrailSettingsExample} />

## 턴 감지/음성 활동 감지

Realtime 세션은 사용자가 말하기 시작했음을 자동으로 감지하고 Realtime API의 기본 제공 [음성 활동 감지 모드](https://platform.openai.com/docs/guides/realtime-vad)를 사용해 새로운 턴을 트리거합니다.

세션에 `turnDetection` 객체를 전달해서 음성 활동 감지 모드를 변경할 수 있습니다.

<Code lang="typescript" code={turnDetectionExample} />

턴 감지 설정을 조정하면 원치 않는 인터럽션과 침묵 처리를 보정하는 데 도움이 됩니다. 다양한 설정에 대한 자세한 내용은 [Realtime API 문서](https://platform.openai.com/docs/guides/realtime-vad)를 참고하세요

## 인터럽션(중단 처리)

기본 제공 음성 활동 감지를 사용하는 경우, 사용자가 에이전트의 발화 도중 말하면 자동으로
에이전트가 이를 감지하고 발화 내용에 기반해 컨텍스트를 업데이트합니다. 또한
`audio_interrupted` 이벤트를 발생시킵니다. 이는 모든 오디오 재생을 즉시 중지하는 데 사용할 수 있습니다(WebSocket 연결에만 적용).

<Code lang="typescript" code={audioInterruptedExample} />

수동으로 인터럽션을 수행하고 싶다면, 예를 들어 UI에 "중지" 버튼을 제공하려는 경우
`interrupt()`를 직접 호출할 수 있습니다:

<Code lang="typescript" code={sessionInterruptExample} />

어느 쪽이든 Realtime 세션은 에이전트의 생성 중단, 사용자에게 말한 내용의 지식 절단, 히스토리 업데이트를 모두 처리합니다.

에이전트에 WebRTC로 연결하는 경우 오디오 출력도 지웁니다. WebSocket을 사용하는 경우에는 대기열에 재생되도록 올라간 오디오의 재생을 직접 중지하는 처리를 해야 합니다.

## 텍스트 입력

에이전트에 텍스트 입력을 보내려면 `RealtimeSession`의 `sendMessage` 메서드를 사용할 수 있습니다.

이는 사용자가 에이전트와 양 modalities로 상호작용할 수 있게 하거나, 대화에 추가 컨텍스트를 제공하려는 경우에 유용합니다.

<Code lang="typescript" code={sendMessageExample} />

## 대화 기록 관리

`RealtimeSession`은 `history` 속성에서 대화 기록을 자동으로 관리합니다:

이를 사용해 고객에게 히스토리를 렌더링하거나 추가 작업을 수행할 수 있습니다. 대화가 진행되는 동안 히스토리는 계속 변경되므로 `history_updated` 이벤트를 수신할 수 있습니다.

히스토리를 수정하고 싶다면, 메시지를 완전히 제거하거나 전사를 업데이트하는 등의 작업을 `updateHistory` 메서드로 수행할 수 있습니다.

<Code lang="typescript" code={updateHistoryExample} />

### 제한사항

1. 현재로서는 함수 도구 호출을 나중에 업데이트/변경할 수 없습니다
2. 히스토리의 텍스트 출력에는 전사와 텍스트 모달리티 활성화가 필요합니다
3. 인터럽션으로 인해 잘린 응답에는 전사가 없습니다

## 도구를 통한 위임

![도구를 통한 위임](https://cdn.openai.com/API/docs/diagram-speech-to-speech-agent-tools.png)

대화 기록과 도구 호출을 결합하면, 더 복잡한 작업을 수행하기 위해 대화를 다른 백엔드 에이전트에 위임하고 그 결과를 사용자에게 다시 전달할 수 있습니다.

<Code lang="typescript" code={delegationAgentExample} />

아래 코드는 서버에서 실행됩니다. 이 예시에서는 Next.js의 Server Actions를 통해 실행됩니다.

<Code lang="typescript" code={serverAgentExample} />
