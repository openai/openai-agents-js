---
title: 모델 컨텍스트 프로토콜 (MCP)
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import hostedConnectorExample from '../../../../../../examples/docs/mcp/hostedConnector.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';
import toolFilterExample from '../../../../../../examples/docs/mcp/tool-filter.ts?raw';

[**Model Context Protocol (MCP)**](https://modelcontextprotocol.io)은 애플리케이션이 LLM에 도구와 컨텍스트를 제공하는 방식을 표준화하는 오픈 프로토콜입니다. MCP 문서에서 인용:

> MCP는 애플리케이션이 LLM에 컨텍스트를 제공하는 방식을 표준화한 오픈 프로토콜입니다. MCP를 AI 애플리케이션용 USB‑C 포트라고 생각해 보세요. USB‑C가 다양한 주변기기 및 액세서리에 기기를 연결하는 표준화된 방식을 제공하듯, MCP는 AI 모델을 서로 다른 데이터 소스와 도구에 연결하는 표준화된 방식을 제공합니다.

이 SDK가 지원하는 MCP 서버 유형은 세 가지입니다:

1. **호스티드 MCP 서버 도구** – [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp)가 도구로 사용하는 원격 MCP 서버
2. **Streamable HTTP MCP 서버** – [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http)를 구현한 로컬 또는 원격 서버
3. **Stdio MCP 서버** – 표준 입출력으로 접근하는 서버(가장 단순한 옵션)

사용 사례에 따라 서버 유형을 선택하세요:

| 필요한 것                                                         | 권장 옵션               |
| ----------------------------------------------------------------- | ----------------------- |
| 기본 OpenAI responses 모델로 공개 접근 가능한 원격 서버 호출      | **1. Hosted MCP tools** |
| 공개 접근 가능한 원격 서버를 사용하되 도구 호출은 로컬에서 트리거 | **2. Streamable HTTP**  |
| 로컬에서 실행 중인 Streamable HTTP 서버 사용                      | **2. Streamable HTTP**  |
| OpenAI-Responses 이외의 모델로 모든 Streamable HTTP 서버 사용     | **2. Streamable HTTP**  |
| 표준 I/O 프로토콜만 지원하는 로컬 MCP 서버와 작업                 | **3. Stdio**            |

## 1. Hosted MCP 서버 도구

호스티드 툴은 전체 왕복 과정을 모델 내부로 밀어 넣습니다. 코드가 MCP 서버를 호출하는 대신, OpenAI Responses API가 원격 도구 엔드포인트를 호출하고 결과를 모델로 스트리밍합니다.

다음은 호스티드 MCP 툴을 사용하는 가장 간단한 예시입니다. 원격 MCP 서버의 레이블과 URL을 `hostedMcpTool` 유틸리티 함수에 전달할 수 있으며, 이는 호스티드 MCP 서버 도구를 생성하는 데 유용합니다.

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

그런 다음 `run` 함수를 사용해 에이전트를 실행할 수 있습니다(또는 사용자 정의한 `Runner` 인스턴스의 `run` 메서드):

<Code
  lang="typescript"
  code={hostedExample}
  title="Run with hosted MCP tools"
/>

증분 MCP 결과를 스트리밍하려면 `Agent`를 실행할 때 `stream: true`를 전달하세요:

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="Run with hosted MCP tools (streaming)"
/>

#### 선택적 승인 흐름

민감한 작업의 경우 개별 도구 호출에 대한 인간 승인 요구가 가능합니다. `requireApproval: 'always'` 또는 도구 이름을 `'never'`/`'always'`에 매핑하는 세분화된 객체를 전달하세요.

도구 호출의 안전성을 프로그램적으로 판단할 수 있다면 [`onApproval` 콜백](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts)을 사용해 승인 또는 거부할 수 있습니다. 인간 승인이 필요한 경우, 로컬 함수 도구와 동일하게 `interruptions`를 사용하는 [휴먼 인 더 루프 (HITL)](/openai-agents-js/ko/guides/human-in-the-loop/) 접근을 사용할 수 있습니다.

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="Human in the loop with hosted MCP tools"
/>

### 커넥터 기반 호스티드 서버

호스티드 MCP는 OpenAI 커넥터도 지원합니다. `serverUrl`을 제공하는 대신 커넥터의 `connectorId`와 `authorization` 토큰을 전달하세요. 그러면 Responses API가 인증을 처리하고 커넥터의 도구를 호스티드 MCP 인터페이스를 통해 노출합니다.

<Code
  lang="typescript"
  code={hostedConnectorExample}
  title="Connector-backed hosted MCP tool"
/>

이 예시에서 `GOOGLE_CALENDAR_AUTHORIZATION` 환경 변수는 Google OAuth Playground에서 얻은 OAuth 토큰을 보관하며, 커넥터 기반 서버가 Calendar API를 호출하도록 승인합니다. 스트리밍까지 시연하는 실행 가능한 샘플은 [`examples/connectors`](https://github.com/openai/openai-agents-js/tree/main/examples/connectors)를 참고하세요.

완전한 동작 샘플(호스티드 툴/Streamable HTTP/stdio + 스트리밍, HITL, onApproval)은 GitHub 리포지토리의 [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp)에 있습니다.

## 2. Streamable HTTP MCP 서버

에이전트가 로컬 또는 원격의 Streamable HTTP MCP 서버와 직접 통신하는 경우, 서버의 `url`, `name` 및 선택적 설정과 함께 `MCPServerStreamableHttp`를 생성하세요:

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="Run with Streamable HTTP MCP servers"
/>

생성자는 `authProvider`, `requestInit`, `fetch`, `reconnectionOptions`, `sessionId` 같은 MCP TypeScript‑SDK 추가 옵션도 받습니다. 자세한 내용은 [MCP TypeScript SDK 리포지토리](https://github.com/modelcontextprotocol/typescript-sdk)와 문서를 참조하세요.

## 3. Stdio MCP 서버

표준 입출력만 노출하는 서버의 경우 `fullCommand`로 `MCPServerStdio`를 생성하세요:

<Code
  lang="typescript"
  code={stdioExample}
  title="Run with Stdio MCP servers"
/>

## 참고 사항

**Streamable HTTP** 및 **Stdio** 서버의 경우, `Agent`가 실행될 때마다 사용 가능한 도구를 발견하기 위해 `list_tools()`를 호출할 수 있습니다. 이 왕복은 특히 원격 서버에서는 지연을 늘릴 수 있으므로, `MCPServerStdio` 또는 `MCPServerStreamableHttp`에 `cacheToolsList: true`를 전달해 메모리에 결과를 캐시할 수 있습니다.

도구 목록이 변경되지 않음을 확신할 때만 활성화하세요. 이후 캐시를 무효화하려면 서버 인스턴스에서 `invalidateToolsCache()`를 호출하세요.

### 도구 필터링

`createMCPToolStaticFilter`를 통한 정적 필터 또는 사용자 정의 함수를 전달해 각 서버에서 노출되는 도구를 제한할 수 있습니다. 다음은 두 접근을 모두 보여주는 결합 예시입니다:

<Code lang="typescript" code={toolFilterExample} title="Tool filtering" />

## 추가 자료

- [Model Context Protocol](https://modelcontextprotocol.io/) – 공식 명세
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) – 위에서 참조한 실행 가능한
  데모
