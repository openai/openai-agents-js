---
title: 세션
description: Persist multi-turn conversation history so agents can resume context across runs.
---

import { Code } from '@astrojs/starlight/components';
import sessionsQuickstart from '../../../../../../examples/docs/sessions/basicSession.ts?raw';
import manageHistory from '../../../../../../examples/docs/sessions/manageHistory.ts?raw';
import customSession from '../../../../../../examples/docs/sessions/customSession.ts?raw';
import sessionInputCallback from '../../../../../../examples/docs/sessions/sessionInputCallback.ts?raw';
import responsesCompactionSession from '../../../../../../examples/docs/sessions/responsesCompactionSession.ts?raw';
import manualCompactionSession from '../../../../../../examples/docs/sessions/responsesCompactionManualSession.ts?raw';

세션은 Agents SDK에 **지속 메모리 계층**을 제공합니다. `Session` 인터페이스를 구현한 어떤 객체든 `Runner.run`에 제공하면, 나머지는 SDK가 처리합니다. 세션이 있으면 러너는 자동으로 다음을 수행합니다.

1. 이전에 저장된 대화 항목을 가져와 다음 턴의 앞에 추가합니다.
2. 각 실행이 완료된 후 새로운 사용자 입력과 어시스턴트 출력을 영구 저장합니다.
3. 새 사용자 텍스트로 러너를 호출하든, 인터럽션(중단 처리)된 `RunState`에서 재개하든, 향후 턴을 위해 세션을 유지합니다.

이로써 `toInputList()`를 수동으로 호출하거나 턴 사이에 히스토리를 이어 붙일 필요가 없습니다. TypeScript SDK에는 두 가지 구현이 포함되어 있습니다: Conversations API용 `OpenAIConversationsSession`과 로컬 개발용 `MemorySession`. 둘 다 `Session` 인터페이스를 공유하므로 직접 스토리지 백엔드를 연결할 수 있습니다. Conversations API 외에도 영감을 얻으려면 `examples/memory/` 아래의 샘플 세션 백엔드(Prisma, 파일 기반 등)를 살펴보세요. OpenAI Responses 모델을 사용하는 경우, `OpenAIResponsesCompactionSession`으로 어떤 세션이든 래핑하여 [`responses.compact`](https://platform.openai.com/docs/api-reference/responses/compact)로 저장된 대화를 자동으로 축약하세요.

> 팁: 이 페이지의 `OpenAIConversationsSession` 예제를 실행하려면 `OPENAI_API_KEY` 환경 변수를 설정하세요(또는 세션을 생성할 때 `apiKey`를 제공). 그러면 SDK가 Conversations API를 호출할 수 있습니다.

---

## 빠른 시작

`OpenAIConversationsSession`을 사용해 [Conversations API](https://platform.openai.com/docs/api-reference/conversations)와 메모리를 동기화하거나, 다른 `Session` 구현으로 교체하세요.

<Code
  lang="typescript"
  code={sessionsQuickstart}
  title="Use the Conversations API as session memory"
/>

동일한 세션 인스턴스를 재사용하면 에이전트가 매 턴마다 전체 대화 히스토리를 전달받고, 새 항목도 자동으로 영구 저장합니다. 다른 `Session` 구현으로 전환해도 다른 코드 변경은 필요 없습니다.

`OpenAIConversationsSession` 생성자 옵션:

| Option           | Type     | Notes                                                          |
| ---------------- | -------- | -------------------------------------------------------------- |
| `conversationId` | `string` | 기존 대화를 재사용하며, 없으면 지연 생성 대신 즉시 지정합니다. |
| `client`         | `OpenAI` | 사전 구성된 OpenAI 클라이언트를 전달합니다.                    |
| `apiKey`         | `string` | 내부 OpenAI 클라이언트 생성 시 사용할 API 키입니다.            |
| `baseURL`        | `string` | OpenAI 호환 엔드포인트의 기본 URL입니다.                       |
| `organization`   | `string` | 요청에 사용할 OpenAI 조직 ID입니다.                            |
| `project`        | `string` | 요청에 사용할 OpenAI 프로젝트 ID입니다.                        |

세션을 구성하기 전에 대화 ID를 미리 만들어야 한다면,
`startOpenAIConversationsSession(client?)`를 사용하고 반환된 ID를 `conversationId`로 전달하세요.

---

## 러너의 세션 사용 방식

- **각 실행 전** 세션 히스토리를 가져와 새 턴 입력과 병합한 뒤, 결합된 목록을 에이전트에 전달합니다.
- **비스트리밍 실행 후** 한 번의 `session.addItems()` 호출로 최신 턴의 원본 사용자 입력과 모델 출력을 모두 영구 저장합니다.
- **스트리밍 실행의 경우** 사용자 입력을 먼저 기록하고, 턴이 완료되면 스트리밍된 출력을 추가합니다.
- **`RunResult.state`에서 재개할 때**(승인 또는 기타 인터럽션) 동일한 `session`을 계속 전달하세요. 재개된 턴은 입력을 다시 준비하지 않고 메모리에 추가됩니다.

---

## 히스토리 검사 및 편집

세션은 "되돌리기", "대화 지우기", 감사 기능을 구축할 수 있도록 간단한 CRUD 헬퍼를 제공합니다.

<Code
  lang="typescript"
  code={manageHistory}
  title="Read and edit stored items"
/>

`session.getItems()`는 저장된 `AgentInputItem[]`를 반환합니다. `popItem()`을 호출하면 마지막 항목을 제거합니다. 에이전트를 다시 실행하기 전 사용자 정정에 유용합니다.

---

## 스토리지를 직접 제공

`Session` 인터페이스를 구현하여 Redis, DynamoDB, SQLite 또는 기타 데이터스토어에 메모리를 저장하세요. 필요한 비동기 메서드는 다섯 가지뿐입니다.

<Code
  lang="typescript"
  code={customSession}
  title="Custom in-memory session implementation"
/>

커스텀 세션을 사용하면 보존 정책을 적용하고, 암호화를 추가하거나, 영구 저장 전에 각 대화 턴에 메타데이터를 첨부할 수 있습니다.

---

## 히스토리와 신규 항목의 병합 제어

실행 입력으로 `AgentInputItem` 배열을 전달할 때 `sessionInputCallback`을 제공하여 저장된 히스토리와 결정적으로 병합하세요. 러너는 기존 히스토리를 로드하고, **모델 호출 전에** 콜백을 호출하며, 반환된 배열을 해당 턴의 전체 입력으로 모델에 전달합니다. 이 훅은 오래된 항목을 잘라내거나, 도구 결과의 중복을 제거하거나, 모델이 보길 원하는 컨텍스트만 강조하는 데 이상적입니다.

<Code
  lang="typescript"
  code={sessionInputCallback}
  title="Truncate history with sessionInputCallback"
/>

문자열 입력의 경우 러너가 히스토리를 자동 병합하므로 콜백은 선택 사항입니다.

---

## 승인 및 재개 가능한 실행 처리

휴먼인더루프 (HITL) 흐름은 종종 승인을 기다리기 위해 실행을 일시 중지합니다:

```typescript
const result = await runner.run(agent, 'Search the itinerary', {
  session,
  stream: true,
});

if (result.requiresApproval) {
  // ... collect user feedback, then resume the agent in a later turn
  const continuation = await runner.run(agent, result.state, { session });
  console.log(continuation.finalOutput);
}
```

이전에 얻은 `RunState`에서 재개하면, 새 턴은 동일한 메모리 레코드에 추가되어 단일 대화 히스토리가 보존됩니다. 휴먼인더루프 (HITL) 흐름은 완전히 호환되며—승인 체크포인트는 계속 `RunState`를 통해 왕복되는 한편, 세션은 전사를 완전하게 유지합니다.

---

## OpenAI Responses 히스토리 자동 압축

`OpenAIResponsesCompactionSession`은 어떤 `Session`이든 데코레이팅하며, OpenAI Responses API에 의존해 전사를 짧게 유지합니다. 각 턴을 영구 저장한 후 러너는 최신 `responseId`를 `runCompaction`에 전달하고, 이때 의사결정 훅이 true를 반환하면 `responses.compact`를 호출합니다. 기본 트리거는 최소 10개의 사용자 이외 항목이 누적되면 한 번 압축합니다. 토큰 수나 사용자 정의 휴리스틱에 기반하도록 `shouldTriggerCompaction`을 재정의하세요. 이 데코레이터는 압축된 출력으로 기본 세션을 지우고 다시 작성하므로, 서버가 관리하는 다른 방식의 히스토리를 사용하는 `OpenAIConversationsSession`과는 함께 사용하지 마세요.

<Code
  lang="typescript"
  code={responsesCompactionSession}
  title="Decorate a session with OpenAIResponsesCompactionSession"
/>

`OpenAIResponsesCompactionSession` 생성자 옵션:

| Option                    | Type                                          | Notes                                                                                           |
| ------------------------- | --------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| `client`                  | `OpenAI`                                      | `responses.compact`에 사용할 OpenAI 클라이언트입니다.                                           |
| `underlyingSession`       | `Session`                                     | 압축된 항목으로 지우고/다시 쓸 기본 세션 스토어입니다 (`OpenAIConversationsSession`이면 안 됨). |
| `model`                   | `OpenAI.ResponsesModel`                       | 컴팩션 요청에 사용할 모델입니다.                                                                |
| `compactionMode`          | `'auto' \| 'previous_response_id' \| 'input'` | 서버 응답 체이닝을 사용할지, 로컬 입력 항목을 사용할지 제어합니다.                              |
| `shouldTriggerCompaction` | `(context) => boolean \| Promise<boolean>`    | `responseId`, `compactionMode`, 후보 항목, 현재 세션 항목에 기반한 사용자 정의 트리거 훅입니다. |

`runCompaction(args)` 옵션:

| Option           | Type                                          | Notes                                                             |
| ---------------- | --------------------------------------------- | ----------------------------------------------------------------- |
| `responseId`     | `string`                                      | `previous_response_id` 모드에서 사용할 최신 Responses API 응답 ID |
| `compactionMode` | `'auto' \| 'previous_response_id' \| 'input'` | 구성된 모드를 호출 단위로 선택적으로 재정의합니다.                |
| `store`          | `boolean`                                     | 마지막 실행이 서버 상태를 저장했는지 여부입니다.                  |
| `force`          | `boolean`                                     | `shouldTriggerCompaction`을 우회하고 즉시 압축합니다.             |

### 저지연 스트리밍을 위한 수동 압축

압축은 기본 세션을 지우고 다시 작성하므로, SDK는 스트리밍 실행을 resolve하기 전에 이를 기다립니다. 압축이 무거우면 마지막 출력 토큰 이후에도 `result.completed`가 몇 초간 대기 상태일 수 있습니다. 저지연 스트리밍이나 더 빠른 턴 전환이 필요하면 자동 압축을 비활성화하고, 턴 사이(또는 유휴 시간)마다 `runCompaction`을 직접 호출하세요.

<Code
  lang="typescript"
  code={manualCompactionSession}
  title="Disable auto-compaction and compact between turns"
/>

아카이브하거나 핸드오프하기 전에 언제든지 `runCompaction({ force: true })`를 호출해 히스토리를 축소할 수 있습니다. `DEBUG=openai-agents:openai:compaction`으로 디버그 로그를 활성화해 컴팩션 결정을 트레이싱하세요.
