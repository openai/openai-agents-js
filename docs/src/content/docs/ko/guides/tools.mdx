---
title: 도구
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../../examples/docs/tools/mcpLocalServer.ts?raw';

도구를 사용하면 에이전트가 **행동을 수행**할 수 있습니다. 데이터 가져오기, 외부 API 호출, 코드 실행, 심지어 컴퓨터 사용까지 가능합니다. JavaScript/TypeScript SDK는 다섯 가지 카테고리를 지원합니다:

1. **OpenAI 호스트하는 도구** – OpenAI 서버에서 모델과 함께 실행됩니다. _(웹 검색, 파일 검색, Code Interpreter, 이미지 생성)_
2. **로컬 내장 도구** – 여러분의 환경에서 실행됩니다. _(컴퓨터 사용, shell, apply_patch)_
3. **함수 도구** – 로컬 함수를 JSON 스키마로 감싸 LLM이 호출할 수 있게 합니다
4. **도구로서의 에이전트** – 전체 에이전트를 호출 가능한 도구로 노출합니다
5. **MCP 서버** – Model context protocol 서버를 연결합니다(로컬 또는 원격)

---

## 1. 호스티드 도구 (OpenAI Responses API)

`OpenAIResponsesModel`을 사용할 때 다음 내장 도구들을 추가할 수 있습니다:

| 도구             | 타입 문자열          | 목적                               |
| ---------------- | -------------------- | ---------------------------------- |
| 웹 검색          | `'web_search'`       | 인터넷 검색                        |
| 파일/검색 검색   | `'file_search'`      | OpenAI에 호스팅된 벡터 스토어 질의 |
| Code Interpreter | `'code_interpreter'` | 샌드박스 환경에서 코드 실행        |
| 이미지 생성      | `'image_generation'` | 텍스트를 기반으로 이미지 생성      |

<Code lang="typescript" code={toolsHostedToolsExample} title="Hosted tools" />

정확한 매개변수는 OpenAI Responses API와 동일합니다. `rankingOptions`나 시맨틱 필터 같은 고급 옵션은 공식 문서를 참고하세요.

---

## 2. 로컬 내장 도구

로컬 내장 도구는 여러분의 환경에서 실행되며 구현을 제공해야 합니다:

- **컴퓨터 사용** – `Computer` 인터페이스를 구현하고 `computerTool()`에 전달
- **Shell** – `Shell` 인터페이스를 구현하고 `shellTool()`에 전달
- **Apply patch** – `Editor` 인터페이스를 구현하고 `applyPatchTool()`에 전달

이들 도구는 로컬에서 실행되며 OpenAI가 **호스팅하지 않습니다**. 런타임에서 파일, 터미널 또는 GUI 자동화에 직접 접근해야 할 때 사용하세요. 도구 호출은 여전히 OpenAI 모델의 응답에 의해 요청되지만, 애플리케이션이 이를 로컬에서 실행해야 합니다.

<Code
  lang="typescript"
  code={localBuiltInToolsExample}
  title="Local built-in tools"
/>

---

## 3. 함수 도구

`tool()` 헬퍼로 **어떤** 함수든 도구로 바꿀 수 있습니다.

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="Function tool with Zod parameters"
/>

### 옵션 참조

| 필드               | 필수   | 설명                                                                                                                                                                |
| ------------------ | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`             | 아니오 | 기본값은 함수 이름입니다(예: `get_weather`)                                                                                                                         |
| `description`      | 예     | LLM에 표시되는 명확하고 사람이 읽기 쉬운 설명                                                                                                                       |
| `parameters`       | 예     | Zod 스키마 또는 원문 JSON 스키마 객체. Zod 매개변수를 사용하면 자동으로 **strict** 모드가 활성화됩니다                                                              |
| `strict`           | 아니오 | `true`(기본값)일 때 인수가 검증에 실패하면 SDK가 모델 오류를 반환. 유사 매칭이 필요하면 `false`로 설정                                                              |
| `execute`          | 예     | `(args, context) => string \| unknown \| Promise<...>` – 비즈니스 로직. 문자열이 아닌 출력은 모델을 위해 직렬화됩니다. 두 번째 선택적 매개변수는 `RunContext`입니다 |
| `errorFunction`    | 아니오 | 내부 오류를 사용자에게 표시할 문자열로 변환하는 커스텀 핸들러 `(context, error) => string`                                                                          |
| `needsApproval`    | 아니오 | 실행 전에 인간 승인 필요. [휴먼 인 더 루프 (HITL)](/openai-agents-js/ko/guides/human-in-the-loop) 가이드를 참고하세요                                               |
| `isEnabled`        | 아니오 | 실행별로 조건부 노출. 불리언 또는 프레디케이트 허용                                                                                                                 |
| `inputGuardrails`  | 아니오 | 도구 실행 전에 실행되는 가드레일. 거부하거나 throw할 수 있음. [가드레일](/openai-agents-js/ko/guides/guardrails#tool-guardrails) 참고                               |
| `outputGuardrails` | 아니오 | 도구 실행 후에 실행되는 가드레일. 거부하거나 throw할 수 있음. [가드레일](/openai-agents-js/ko/guides/guardrails#tool-guardrails) 참고                               |

### 비 엄격 JSON 스키마 도구

모델이 잘못되었거나 부분적인 입력을 _추측_ 하도록 하려면 원문 JSON 스키마를 사용할 때 strict 모드를 비활성화하세요:

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="Non-strict JSON schema tools"
/>

---

## 4. 도구로서의 에이전트

대화를 완전히 핸드오프하지 않고 한 에이전트가 다른 에이전트를 _지원_ 하도록 하고 싶을 수 있습니다. `agent.asTool()`을 사용하세요:

<Code lang="typescript" code={agentsAsToolsExample} title="Agents as tools" />

내부적으로 SDK는 다음을 수행합니다:

- 단일 `input` 매개변수를 가진 함수 도구를 생성
- 도구가 호출되면 해당 입력으로 하위 에이전트를 실행
- 마지막 메시지 또는 `customOutputExtractor`가 추출한 출력을 반환

에이전트를 도구로 실행하면, Agents SDK는 기본 설정으로 러너를 생성하고 함수 실행 내에서 그 러너로 에이전트를 실행합니다. `runConfig` 또는 `runOptions`의 속성을 제공하려면 `asTool()` 메서드에 전달하여 러너 동작을 커스터마이즈할 수 있습니다.

또한 `asTool()` 옵션을 통해 에이전트 도구에 `needsApproval`과 `isEnabled`를 설정하여 휴먼‑인‑더‑루프 플로우 및 조건부 도구 사용과 통합할 수 있습니다.

### 에이전트 도구의 스트리밍 이벤트

에이전트 도구는 모든 중첩 실행 이벤트를 앱으로 스트리밍할 수 있습니다. 도구를 구성하는 방식에 맞는 훅 스타일을 선택하세요:

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="Streaming agent tools"
/>

- 이벤트 타입은 `RunStreamEvent['type']`과 일치: `raw_model_stream_event`, `run_item_stream_event`, `agent_updated_stream_event`
- `onStream`은 가장 단순한 “모두 수신” 방식으로, 도구를 인라인으로 선언할 때 잘 동작합니다(`tools: [agent.asTool({ onStream })]`). 이벤트별 라우팅이 필요 없다면 사용하세요
- `on(eventName, handler)`는 선택적으로(또는 `'*'`로) 구독할 수 있어, 더 세밀한 처리가 필요하거나 생성 이후 리스너를 붙이고 싶을 때 적합합니다
- `onStream` 또는 어떤 `on(...)` 핸들러든 제공하면 에이전트‑as‑도구는 자동으로 스트리밍 모드로 실행됩니다. 제공하지 않으면 비‑스트리밍 경로로 유지됩니다
- 핸들러는 병렬로 호출되므로 느린 `onStream` 콜백이 `on(...)` 핸들러를 블로킹하지 않습니다(그 반대도 마찬가지)
- `toolCallId`는 도구가 모델의 도구 호출을 통해 호출되었을 때 제공됩니다. 직접 `invoke()` 호출하거나 공급자 특성에 따라 생략될 수 있습니다

---

## 5. MCP 서버

[Model context protocol (MCP)](https://modelcontextprotocol.io/) 서버를 통해 도구를 노출하고 에이전트에 연결할 수 있습니다.
예를 들어, `MCPServerStdio`를 사용해 stdio MCP 서버를 실행하고 연결할 수 있습니다:

<Code lang="typescript" code={mcpLocalServer} title="Local MCP server" />

완전한 예시는 [`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts)를 참고하세요. 또한 MCP 서버 도구 통합에 대한 종합 가이드를 찾고 있다면 [모델 컨텍스트 프로토콜 (MCP)](/openai-agents-js/ko/guides/mcp) 가이드를 참고하세요.

---

## 도구 사용 동작

모델이 언제, 어떻게 도구를 사용해야 하는지 제어하려면 [에이전트](/openai-agents-js/ko/guides/agents#forcing-tool-use) 가이드를 참고하세요 (`tool_choice`, `toolUseBehavior` 등).

---

## 모범 사례

- **짧고 명확한 설명** – 도구가 _무엇을_ 하는지와 *언제 사용하는지*를 설명
- **입력 검증** – 가능한 경우 엄격한 JSON 검증을 위해 Zod 스키마 사용
- **에러 핸들러에서 부작용 회피** – `errorFunction`은 도움 되는 문자열을 반환해야 하며, throw하지 않아야 함
- **도구당 한 가지 책임** – 작고 조합 가능한 도구가 더 나은 모델 추론으로 이어짐

---

## 다음 단계

- [도구 사용 강제](/openai-agents-js/ko/guides/agents#forcing-tool-use)에 대해 알아보기
- 도구 입력 또는 출력을 검증하기 위해 [가드레일](/openai-agents-js/ko/guides/guardrails) 추가
- [`tool()`](/openai-agents-js/openai/agents/functions/tool) 및 다양한 호스티드 도구 타입에 대한 TypeDoc 레퍼런스 살펴보기
