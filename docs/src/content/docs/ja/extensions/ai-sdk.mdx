---
title: AI SDK で任意モデルを指定
description: Connect your Agents SDK agents to any model through the Vercel's AI SDK
---

import { Aside, Steps, Code } from '@astrojs/starlight/components';
import aiSdkSetupExample from '../../../../../../examples/docs/extensions/ai-sdk-setup.ts?raw';

<Aside type="caution">
  このアダプターはまだベータ版です。特に小規模なモデルプロバイダーでは問題が発生する可能性があります。問題があれば
  [GitHub issues](https://github.com/openai/openai-agents-js/issues)
  からご報告ください。迅速に修正します。
</Aside>

Agents SDK は標準で Responses API や Chat Completions API を介して OpenAI モデルと連携します。ただし、別のモデルを使用したい場合は、[Vercel の AI SDK](https://sdk.vercel.ai/) が提供する幅広い対応モデルを、このアダプターを通じて Agents SDK に取り込むことができます。

## セットアップ

<Steps>

1. 拡張機能パッケージをインストールして AI SDK アダプターを導入します:

   ```bash
   npm install @openai/agents-extensions
   ```

2. [Vercel の AI SDK](https://ai-sdk.dev/docs/foundations/providers-and-models) から使用したいモデルのパッケージを選び、インストールします:

   ```bash
   npm install @ai-sdk/openai
   ```

3. アダプターとモデルをインポートしてエージェントに接続します:

   ```typescript
   import { openai } from '@ai-sdk/openai';
   import { aisdk } from '@openai/agents-extensions/ai-sdk';
   ```

4. エージェントで使用するモデルのインスタンスを初期化します:

   ```typescript
   const model = aisdk(openai('gpt-5-mini'));
   ```

</Steps>

<Aside type="caution">
  `specificationVersion` が `v2` または `v3` の AI SDK
  プロバイダーに対応しています。特別な理由で旧来の v1
  プロバイダースタイルを使い続ける必要がある場合は、
  [examples/ai-sdk-v1](https://github.com/openai/openai-agents-js/tree/main/examples/ai-sdk-v1)
  からモジュールをコピーしてプロジェクトに含めてください。
</Aside>

## 例

<Code
  lang="typescript"
  code={aiSdkSetupExample}
  title="AI SDK のセットアップ"
/>

## プロバイダー メタデータの受け渡し

メッセージにプロバイダー固有のオプションを送る必要がある場合は、`providerMetadata` を通して渡します。値は基盤となる AI SDK モデルにそのまま転送されます。たとえば、Agents SDK で次の `providerData`

```ts
providerData: {
  anthropic: {
    cacheControl: {
      type: 'ephemeral';
    }
  }
}
```

は、AI SDK 連携を使用する場合は次のようになります

```ts
providerMetadata: {
  anthropic: {
    cacheControl: {
      type: 'ephemeral';
    }
  }
}
```

## AI SDK UI ストリーム ヘルパー

`@openai/agents-extensions/ai-sdk-ui` は、Agents SDK のストリームを AI SDK UI ルートに接続するためのレスポンスヘルパーを提供します:

- `createAiSdkTextStreamResponse(source, options?)`: プレーンテキストのストリーミングレスポンス
- `createAiSdkUiMessageStreamResponse(source, options?)`: `UIMessageChunk` のストリーミングレスポンス

どちらのヘルパーも `StreamedRunResult`、ストリーム互換のソース、または互換ラッパーオブジェクトを受け取り、ストリーミングに適したヘッダー付きの `Response` を返します。

エンドツーエンドの使用例については、このリポジトリ内の `examples/ai-sdk-ui` アプリを参照してください。
