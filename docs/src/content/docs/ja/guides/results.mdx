---
title: エージェントの実行結果
description: Learn how to access the results and output from your agent run
---

import { Code } from '@astrojs/starlight/components';
import handoffFinalOutputTypes from '../../../../../../examples/docs/results/handoffFinalOutputTypes.ts?raw';
import historyLoop from '../../../../../../examples/docs/results/historyLoop.ts?raw';

[エージェントの実行](/openai-agents-js/ja/guides/running-agents)を行うと、次のいずれかを受け取ります:

- `stream: true` を付けずに `run` を呼び出した場合は [`RunResult`](/openai-agents-js/openai/agents/classes/runresult)
- `stream: true` を付けて `run` を呼び出した場合は [`StreamedRunResult`](/openai-agents-js/openai/agents/classes/streamedrunresult)。ストリーミングの詳細は[ストリーミング](/openai-agents-js/ja/guides/streaming)も参照してください

## 最終出力

`finalOutput` プロパティには、最後に実行されたエージェントの最終出力が入ります。結果は次のいずれかです:

- `string` — `outputType` を定義していないエージェントのデフォルト
- `unknown` — エージェントが出力型として JSON スキーマを定義している場合。この場合 JSON はパースされていますが、型の検証は手動で行う必要があります
- `z.infer<outputType>` — エージェントが出力型として Zod スキーマを定義している場合。出力は自動的にこのスキーマでパースされます
- `undefined` — エージェントが出力を生成しなかった場合（たとえば出力前に停止した場合）

異なる出力型を持つハンドオフを使用している場合は、エージェントの作成に `new Agent()` コンストラクターではなく `Agent.create()` メソッドを使用してください。

これにより、SDK がすべての可能なハンドオフにわたる出力型を推論し、`finalOutput` プロパティに対してユニオン型を提供できるようになります。

例:

<Code
  lang="typescript"
  code={handoffFinalOutputTypes}
  title="ハンドオフの最終出力の型"
/>

## 次ターンの入力

次のターンの入力には、以下の 2 通りでアクセスできます:

- `result.history` — 入力とエージェントの出力の両方のコピーを保持
- `result.output` — エージェントのフル実行の出力を保持

`history` は、チャット用途で完全な履歴を維持するのに便利です:

<Code lang="typescript" code={historyLoop} title="履歴ループ" />

## 最後のエージェント

`lastAgent` プロパティには、最後に実行されたエージェントが入ります。アプリによっては、次回 ユーザー が入力するときに便利です。たとえば、言語別エージェントへハンドオフする一次トリアージのエージェントがある場合、最後のエージェントを保存しておき、次回 ユーザー がメッセージを送るときに再利用できます。

ストリーミングモードでは、現在実行中のエージェントに対応する `currentAgent` プロパティへアクセスするのも有用です。

## 新規アイテム

`newItems` プロパティには、実行中に生成された新規アイテムが入ります。アイテムは [`RunItem`](/openai-agents-js/openai/agents/type-aliases/runitem) です。Run item は LLM が生成した元アイテムをラップします。どのエージェントに紐づくイベントかなど、LLM の出力に加えて参照できます。

- [`RunMessageOutputItem`](/openai-agents-js/openai/agents/classes/runmessageoutputitem) は LLM からのメッセージを表します。元アイテムは生成されたメッセージです
- [`RunHandoffCallItem`](/openai-agents-js/openai/agents/classes/runhandoffcallitem) は LLM がハンドオフ ツールを呼び出したことを表します。元アイテムは LLM からのツール呼び出しアイテムです
- [`RunHandoffOutputItem`](/openai-agents-js/openai/agents/classes/runhandoffoutputitem) はハンドオフが発生したことを表します。元アイテムはハンドオフ ツール呼び出しに対するツールのレスポンスです。アイテムからソース/ターゲットのエージェントにもアクセスできます
- [`RunToolCallItem`](/openai-agents-js/openai/agents/classes/runtoolcallitem) は LLM がツールを起動したことを表します
- [`RunToolCallOutputItem`](/openai-agents-js/openai/agents/classes/runtoolcalloutputitem) はツールが呼び出されたことを表します。元アイテムはツールのレスポンスです。アイテムからツールの出力にもアクセスできます
- [`RunReasoningItem`](/openai-agents-js/openai/agents/classes/runreasoningitem) は LLM の reasoning アイテムを表します。元アイテムは生成された reasoning です
- [`RunToolApprovalItem`](/openai-agents-js/openai/agents/classes/runtoolapprovalitem) は LLM がツール呼び出しの承認を要求したことを表します。元アイテムは LLM からのツール呼び出しアイテムです

## 状態

`state` プロパティには、実行の状態が入ります。`result` に付随する情報の大部分は `state` から導出されていますが、`state` はシリアライズ/デシリアライズ可能で、[エラーからの復旧](/openai-agents-js/ja/guides/running-agents#exceptions)や、[`interruption`](#interruptions) に対処するために後続の `run` 呼び出しへの入力としても使用できます。

## 割り込み

エージェントで `needsApproval` を使用している場合、続行前に処理すべき `interruptions` がトリガーされることがあります。その場合、`interruptions` は割り込みの原因となった `ToolApprovalItem`s の配列になります。割り込みの扱い方については、[人間の介入（HITL）](/openai-agents-js/ja/guides/human-in-the-loop)を参照してください。

## その他の情報

### 元レスポンス

`rawResponses` プロパティには、エージェント実行中にモデルが生成した元の LLM レスポンスが入ります。

### 最終レスポンス ID

`lastResponseId` プロパティには、エージェント実行中にモデルが最後に生成したレスポンスの ID が入ります。

### ガードレールの結果

`inputGuardrailResults` と `outputGuardrailResults` プロパティには、存在する場合はガードレールの結果が入ります。ガードレールの結果にはログ記録や保存に有用な情報が含まれることがあるため、参照できるように提供しています。

### 元の入力

`input` プロパティには、run メソッドに渡した元の入力が入ります。多くの場合は不要ですが、必要なときに利用できます。
