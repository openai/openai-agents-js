---
title: コンテキスト管理
description: Learn how to provide local data via RunContext and expose context to the LLM
---

import { Aside, Code } from '@astrojs/starlight/components';
import localContextExample from '../../../../../../examples/docs/context/localContext.ts?raw';

コンテキストは多義的な用語です。考慮すべきコンテキストには大きく 2 つの種類があります:

1. **ローカルコンテキスト**: 実行中にコードがアクセスできるもの。ツールに必要な依存関係やデータ、`onHandoff` のようなコールバック、ライフサイクルフック
2. **エージェント / LLM コンテキスト**: 応答を生成するときに言語モデルが参照できるもの

## ローカルコンテキスト

ローカルコンテキストは `RunContext<T>` 型で表されます。状態や依存関係を保持する任意のオブジェクトを作成し、それを `Runner.run()` に渡します。すべてのツール呼び出しとフックは `RunContext` ラッパーを受け取り、そのオブジェクトを読み取ったり変更したりできます。

<Code
  lang="typescript"
  code={localContextExample}
  title="ローカルコンテキストの例"
/>

単一の実行に参加するすべてのエージェント、ツール、フックは、同じ **型** のコンテキストを使用する必要があります。

ローカルコンテキストの用途例:

- 実行に関するデータ（ユーザー名、 ID など）
- ロガーやデータフェッチャーなどの依存関係
- 補助関数

<Aside type="note">
  コンテキストオブジェクトは LLM に <b>送信されません</b>
  。これは純粋にローカルで、自由に読み書きできます。
</Aside>

## エージェント / LLM コンテキスト

LLM が呼び出されると、参照できるデータは会話履歴から来るものだけです。追加情報を利用可能にするには、次のような選択肢があります:

1. エージェントの `instructions` に追加できます — システムまたは開発者メッセージとも呼ばれます。これは静的な文字列、またはコンテキストを受け取って文字列を返す関数にできます。
2. `Runner.run()` を呼び出すときに `input` に含めることができます。これは instructions の手法に似ていますが、メッセージを [指揮系統](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) の下位に配置できます。
3. 関数ツール経由で公開して、 LLM が必要に応じてデータを取得できるようにできます。
4. ファイル、データベース、または Web からの関連データに基づいて応答を裏付けるために、リトリーバルや Web 検索ツールを使用できます。
