---
title: MCP 連携
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';

[**Model Context Protocol (MCP)**](https://modelcontextprotocol.io) は、アプリケーションが LLM にツールとコンテキストを提供する方法を標準化するオープンプロトコルです。MCP ドキュメントより引用します。

> MCP は、アプリケーションが LLM にコンテキストを提供する方法を標準化するオープンプロトコルです。MCP は AI アプリケーション向けの USB-C ポートのようなものと考えてください。USB-C がデバイスをさまざまな周辺機器やアクセサリーに接続するための標準化された方法を提供するのと同様に、MCP は AI モデルをさまざまなデータソースやツールに接続するための標準化された方法を提供します。

この SDK がサポートする MCP サーバーには次の 3 種類があります。

1. **Hosted MCP-server tools** – [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp) によりツールとして呼び出されるリモート MCP サーバー
2. **Streamable HTTP MCP サーバー** – [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http) を実装したローカルまたはリモートサーバー
3. **Stdio MCP サーバー** – 標準入力/出力経由でアクセスするサーバー（もっともシンプル）

ユースケースに応じてサーバータイプを選択してください。

| 必要なこと                                                                               | 推奨オプション          |
| ---------------------------------------------------------------------------------------- | ----------------------- |
| 公開アクセス可能なリモートサーバーを、デフォルトの OpenAI Responses モデルで呼び出したい | **1. Hosted MCP tools** |
| 公開アクセス可能なリモートサーバーを使用しつつ、ツール呼び出しをローカルでトリガーしたい | **2. Streamable HTTP**  |
| ローカルで動作する Streamable HTTP サーバーを使用したい                                  | **2. Streamable HTTP**  |
| OpenAI 以外の Responses モデルと組み合わせて任意の Streamable HTTP サーバーを使いたい    | **2. Streamable HTTP**  |
| 標準 I/O プロトコルのみをサポートするローカル MCP サーバーと連携したい                   | **3. Stdio**            |

## 1. Hosted MCP サーバーツール

Hosted tool では、往復すべてがモデル内部で完結します。あなたのコードが MCP サーバーを呼び出す代わりに、OpenAI Responses API がリモートツールのエンドポイントを呼び出し、その結果をストリームでモデルに返します。

Hosted MCP サーバーツールを使うもっともシンプルな例を示します。`hostedMcpTool` ユーティリティ関数にリモート MCP サーバーのラベルと URL を渡すだけで作成できます。

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

続いて、`run` 関数（またはカスタマイズした `Runner` インスタンスの `run` メソッド）でエージェントを実行します。

<Code
  lang="typescript"
  code={hostedExample}
  title="Run with hosted MCP tools"
/>

MCP の増分結果をストリーミングする場合は、`Agent` を実行するときに `stream: true` を渡してください。

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="Run with hosted MCP tools (streaming)"
/>

#### オプションの承認フロー

機微な操作の場合、個々のツール呼び出しに人間の承認を必須にできます。`requireApproval: 'always'` を渡すか、ツール名ごとに `'never'` / `'always'` を指定するオブジェクトを渡してください。

ツール呼び出しが安全かどうかをプログラム的に判断できる場合は、[`onApproval` コールバック](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts) を使って承認または拒否できます。人間の承認が必要な場合は、ローカルの関数ツールと同様に `interruptions` を使用した [人間の介入（HITL）](/openai-agents-js/ja/guides/human-in-the-loop/) のアプローチが利用できます。

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="Human in the loop with hosted MCP tools"
/>

ストリーミング、承認、HITL を含む完全な動作例は GitHub リポジトリの [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) にあります。

## 2. Streamable HTTP MCP サーバー

エージェントがローカルまたはリモートの Streamable HTTP MCP サーバーと直接通信する場合は、サーバーの `url`、`name`、オプション設定を指定して `MCPServerStreamableHttp` を生成します。

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="Run with Streamable HTTP MCP servers"
/>

コンストラクターでは `authProvider`, `requestInit`, `reconnectionOptions`, `sessionId` など、MCP TypeScript SDK の追加オプションも指定できます。詳細は [MCP TypeScript SDK リポジトリ](https://github.com/modelcontextprotocol/typescript-sdk) とそのドキュメントをご覧ください。

## 3. Stdio MCP サーバー

標準 I/O のみを公開するサーバーには、`fullCommand` を指定して `MCPServerStdio` を生成します。

<Code
  lang="typescript"
  code={stdioExample}
  title="Run with Stdio MCP servers"
/>

## 知っておくべきその他のポイント

**Streamable HTTP** および **Stdio** サーバーの場合、`Agent` は実行のたびに利用可能なツールを確認するため `list_tools()` を呼び出すことがあります。この往復は、特にリモートサーバーではレイテンシーを増やす可能性があります。ツールリストが変わらないと確信できる場合は、`MCPServerStdio` または `MCPServerStreamableHttp` に `cacheToolsList: true` を渡して結果をメモリにキャッシュできます。

後からキャッシュを無効化したい場合は、サーバーインスタンスの `invalidateToolsCache()` を呼び出してください。

## 参考文献

- [Model Context Protocol](https://modelcontextprotocol.io/) – 公式仕様
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) – 上記で参照した実行可能デモ
