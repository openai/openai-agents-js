---
title: MCP 連携
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';
import toolFilterExample from '../../../../../../examples/docs/mcp/tool-filter.ts?raw';

The [**Model Context Protocol (MCP)**](https://modelcontextprotocol.io) は、アプリケーションが LLM にツールとコンテキストを提供する方法を標準化するオープンなプロトコルです。MCP のドキュメントより:

> MCP は、アプリケーションが LLM にコンテキストを提供する方法を標準化するオープンなプロトコルです。MCP を AI アプリケーション向けの USB-C ポートだと考えてください。USB-C がデバイスをさまざまな周辺機器やアクセサリに接続する標準化された方法を提供するのと同様に、MCP は AI モデルをさまざまなデータソースやツールに接続する標準化された方法を提供します

この SDK がサポートする MCP サーバーは 3 種類あります:

1. **リモート MCP サーバーツール** – [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp) によってツールとして利用されるリモートの MCP サーバー
2. **Streamable HTTP MCP サーバー** – [Streamable HTTP トランスポート](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http) を実装するローカルまたはリモートのサーバー
3. **Stdio MCP サーバー** – 標準入出力経由でアクセスするサーバー（最も簡単な選択肢）

ユースケースに基づいてサーバータイプを選択してください:

| 必要なこと                                                                     | 推奨オプション                     |
| ------------------------------------------------------------------------------ | ---------------------------------- |
| 既定の OpenAI Responses モデルで公開アクセス可能なリモートサーバーを呼び出す   | **1. リモート MCP サーバーツール** |
| 公開アクセス可能なリモートサーバーを使うが、ツール呼び出しはローカルでトリガー | **2. Streamable HTTP**             |
| ローカルで稼働する Streamable HTTP サーバーを使用                              | **2. Streamable HTTP**             |
| OpenAI Responses 以外のモデルで任意の Streamable HTTP サーバーを使用           | **2. Streamable HTTP**             |
| 標準 I/O プロトコルのみをサポートするローカルの MCP サーバーを扱う             | **3. Stdio**                       |

## 1. リモート MCP サーバーツール

組み込みツール（Hosted）は、往復の処理をすべてモデル内で完結させます。あなたのコードが MCP サーバーを呼び出す代わりに、OpenAI Responses API がリモートのツールエンドポイントを起動し、その結果をモデルへストリーミングで返します。

以下は hosted MCP ツールを使う最も簡単な例です。リモートの MCP サーバーのラベルと URL を `hostedMcpTool` ユーティリティ関数に渡せます。これは hosted MCP サーバーツールを作成するのに便利です。

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

続いて、`run` 関数（またはカスタマイズした `Runner` インスタンスの `run` メソッド）でエージェントを実行できます:

<Code
  lang="typescript"
  code={hostedExample}
  title="リモート MCP サーバーツールで実行"
/>

増分の MCP 結果をストリーミングするには、`Agent` を実行する際に `stream: true` を指定します:

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="リモート MCP サーバーツールで実行（ストリーミング）"
/>

#### 任意の承認フロー

機微な操作については、個々のツール呼び出しに対して人による承認を必須にできます。`requireApproval: 'always'` または、ツール名ごとに `'never'`/`'always'` を割り当てるきめ細かなオブジェクトのいずれかを渡してください。

ツール呼び出しが安全かどうかをプログラムで判定できる場合は、ツール呼び出しを承認または却下するために [`onApproval` コールバック](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts) を使用できます。人による承認が必要な場合は、ローカルの 関数ツール と同様に `interruptions` を使って、同じ [人間の介入（HITL）](/openai-agents-js/ja/guides/human-in-the-loop/) のアプローチを利用できます。

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="リモート MCP サーバーツールでの Human in the loop（人間の介入）"
/>

フルに動作するサンプル（Hosted ツール / Streamable HTTP / stdio + ストリーミング、HITL、onApproval）は、GitHub リポジトリの [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) にあります。

## 2. Streamable HTTP MCP サーバー

エージェントがローカルまたはリモートの Streamable HTTP MCP サーバーと直接やり取りする場合、サーバーの `url`、`name`、必要に応じたオプション設定を指定して `MCPServerStreamableHttp` をインスタンス化します:

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="Streamable HTTP MCP サーバーで実行"
/>

コンストラクターは、`authProvider`、`requestInit`、`fetch`、`reconnectionOptions`、`sessionId` などの追加の MCP TypeScript‑SDK オプションも受け付けます。詳細は [MCP TypeScript SDK リポジトリ](https://github.com/modelcontextprotocol/typescript-sdk) とそのドキュメントを参照してください。

## 3. Stdio MCP サーバー

標準 I/O のみを公開するサーバーの場合は、`fullCommand` を指定して `MCPServerStdio` をインスタンス化します:

<Code lang="typescript" code={stdioExample} title="Stdio MCP サーバーで実行" />

## その他の注意点

Streamable HTTP と Stdio のサーバーでは、`Agent` を実行するたびに、利用可能なツールを検出するために `list_tools()` を呼び出す場合があります。特にリモートサーバーでは、この往復がレイテンシの原因となるため、`MCPServerStdio` または `MCPServerStreamableHttp` に `cacheToolsList: true` を渡して、結果をメモリにキャッシュできます。

ツール一覧が変わらないと確信できる場合にのみ有効化してください。後でキャッシュを無効化するには、サーバーインスタンスで `invalidateToolsCache()` を呼び出します。

### ツールのフィルタリング

各サーバーから公開するツールを制限するには、`createMCPToolStaticFilter` による静的フィルター、またはカスタム関数を渡します。両方のアプローチを組み合わせた例を次に示します:

<Code
  lang="typescript"
  code={toolFilterExample}
  title="ツールのフィルタリング"
/>

## 参考資料

- [Model Context Protocol](https://modelcontextprotocol.io/) – 公式仕様
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) – 上記で参照した実行可能な
  デモ
