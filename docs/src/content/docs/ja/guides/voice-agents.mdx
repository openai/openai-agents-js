---
title: 音声エージェントの概要
description: Build realtime voice assistants using RealtimeAgent and RealtimeSession
---

import { Aside, Code, LinkCard } from '@astrojs/starlight/components';
import createAgentExample from '../../../../../../examples/docs/voice-agents/createAgent.ts?raw';
import multiAgentsExample from '../../../../../../examples/docs/voice-agents/multiAgents.ts?raw';
import createSessionExample from '../../../../../../examples/docs/voice-agents/createSession.ts?raw';
import configureSessionExample from '../../../../../../examples/docs/voice-agents/configureSession.ts?raw';
import handleAudioExample from '../../../../../../examples/docs/voice-agents/handleAudio.ts?raw';
import defineToolExample from '../../../../../../examples/docs/voice-agents/defineTool.ts?raw';
import toolApprovalEventExample from '../../../../../../examples/docs/voice-agents/toolApprovalEvent.ts?raw';
import guardrailsExample from '../../../../../../examples/docs/voice-agents/guardrails.ts?raw';
import guardrailSettingsExample from '../../../../../../examples/docs/voice-agents/guardrailSettings.ts?raw';
import audioInterruptedExample from '../../../../../../examples/docs/voice-agents/audioInterrupted.ts?raw';
import sessionInterruptExample from '../../../../../../examples/docs/voice-agents/sessionInterrupt.ts?raw';
import sessionHistoryExample from '../../../../../../examples/docs/voice-agents/sessionHistory.ts?raw';
import historyUpdatedExample from '../../../../../../examples/docs/voice-agents/historyUpdated.ts?raw';
import updateHistoryExample from '../../../../../../examples/docs/voice-agents/updateHistory.ts?raw';
import customWebRTCTransportExample from '../../../../../../examples/docs/voice-agents/customWebRTCTransport.ts?raw';
import websocketSessionExample from '../../../../../../examples/docs/voice-agents/websocketSession.ts?raw';
import transportEventsExample from '../../../../../../examples/docs/voice-agents/transportEvents.ts?raw';
import thinClientExample from '../../../../../../examples/docs/voice-agents/thinClient.ts?raw';

![Realtime Agents](https://cdn.openai.com/API/docs/images/diagram-speech-to-speech.png)

音声エージェントは OpenAI の音声から音声へのモデルを使用して、リアルタイムの音声チャットを提供します。これらのモデルは音声、テキスト、ツール呼び出しのストリーミングに対応し、音声/電話のカスタマーサポート、モバイルアプリの体験、音声チャットのような用途に最適です。

Voice Agents SDK は、[OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime) 向けの TypeScript クライアントを提供します。

<LinkCard
  title="クイックスタート"
  href="/openai-agents-js/ja/guides/voice-agents/quickstart"
  description="OpenAI Agents SDK を使って、数分で最初のリアルタイムの音声アシスタントを構築できます。"
/>

### 主な機能

- WebSocket または WebRTC 接続
- ブラウザおよびバックエンド接続の両方で利用可能
- 音声と割り込みの処理
- ハンドオフ を通じたマルチエージェントのオーケストレーション
- ツールの定義と呼び出し
- モデル出力を監視するカスタム ガードレール
- ストリーミング イベント向けのコールバック
- テキストと音声のエージェントの両方で同じコンポーネントを再利用

音声から音声へのモデルを使うことで、モデルがオーディオをリアルタイムに処理する能力を活用できます。これにより、モデルの動作後にテキストへ文字起こししてから再度音声に変換し直す必要がありません。

![音声から音声へのモデル](https://cdn.openai.com/API/docs/images/diagram-chained-agent.png)
