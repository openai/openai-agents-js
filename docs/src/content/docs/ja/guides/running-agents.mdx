---
title: エージェントの実行
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';
import conversationIdExample from '../../../../../../examples/docs/running-agents/conversationId.ts?raw';
import previousResponseIdExample from '../../../../../../examples/docs/running-agents/previousResponseId.ts?raw';

エージェント は単体では何もしません。`Runner` クラスまたは `run()` ユーティリティで それらを **実行** します。

<Code lang="typescript" code={helloWorldExample} title="シンプルな実行" />

カスタム Runner が不要な場合は、シングルトンのデフォルト `Runner` インスタンスで動作する `run()` ユーティリティも使えます。

あるいは独自の Runner インスタンスを作成できます:

<Code
  lang="typescript"
  code={helloWorldWithRunnerExample}
  title="シンプルな実行"
/>

エージェント を実行すると、最終出力と実行全履歴を含む [エージェントの実行結果](/openai-agents-js/ja/guides/results) オブジェクトを受け取ります。

## エージェントループ

Runner の run メソッドを使うときは、開始する エージェント と入力を渡します。入力は文字列（ユーザー メッセージとして扱われます）か、OpenAI Responses API のアイテムである入力アイテムの一覧のいずれかです。

Runner は次のループを実行します:

1. 現在の入力で現在の エージェント のモデルを呼び出す
2. LLM の応答を確認する
   - **最終出力** → 返す
   - **ハンドオフ** → 新しい エージェント に切り替え、蓄積した会話履歴を保持し、1 に戻る
   - **ツール呼び出し** → ツールを実行し、その結果を会話に追加して、1 に戻る
3. `maxTurns` に達したら [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) を送出する

<Aside type="note">
  LLM
  出力が「最終出力」と見なされる条件は、目的の型のテキスト出力を生成し、ツール呼び出しがないことです。
</Aside>

### Runner のライフサイクル

アプリ起動時に `Runner` を作成し、リクエスト間で再利用します。このインスタンスはモデルプロバイダーやトレーシングオプションといったグローバル設定を保持します。まったく別の構成が必要な場合のみ別の `Runner` を作成してください。シンプルなスクリプトでは内部でデフォルト Runner を使う `run()` を呼ぶこともできます。

## 実行引数

`run()` メソッドへの入力は、実行を開始する初期 エージェント、実行の入力、およびオプションのセットです。

入力は、文字列（ユーザー メッセージとして扱われます）、[input items](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) の一覧、または [Human in the loop (人間の介入)](/openai-agents-js/ja/guides/human-in-the-loop) エージェントを構築している場合は [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) オブジェクトのいずれかです。

追加オプションは次のとおりです:

| Option     | Default | Description                                                                                                                                   |
| ---------- | ------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| `stream`   | `false` | `true` の場合、呼び出しは `StreamedRunResult` を返し、モデルから到着したイベントを逐次送出します                                              |
| `context`  | –       | すべての tool / guardrail / handoff に転送されるコンテキストオブジェクト。詳細は[コンテキスト管理](/openai-agents-js/ja/guides/context)を参照 |
| `maxTurns` | `10`    | セーフティリミット。到達時に [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) を送出します       |
| `signal`   | –       | 取り消し用の `AbortSignal`                                                                                                                    |

## ストリーミング

ストリーミング を使うと、LLM の実行中にストリーミングイベントも受け取れます。ストリームが開始されると、`StreamedRunResult` は新しく生成されたすべての出力を含む、実行に関する完全な情報を保持します。`for await` ループでストリーミングイベントを反復処理できます。詳しくは[ストリーミング](/openai-agents-js/ja/guides/streaming)を参照してください。

## 実行設定

独自の `Runner` インスタンスを作成する場合は、Runner を構成するために `RunConfig` オブジェクトを渡せます。

| Field                       | Type                  | Purpose                                                                       |
| --------------------------- | --------------------- | ----------------------------------------------------------------------------- |
| `model`                     | `string \| Model`     | 実行中の **すべて** の エージェント に対して特定のモデルを強制します          |
| `modelProvider`             | `ModelProvider`       | モデル名を解決します。デフォルトは OpenAI プロバイダーです                    |
| `modelSettings`             | `ModelSettings`       | エージェント個別の設定を上書きするグローバルなチューニング パラメーター       |
| `handoffInputFilter`        | `HandoffInputFilter`  | ハンドオフ時に入力アイテムを変換します（ハンドオフ自体で未定義の場合）        |
| `inputGuardrails`           | `InputGuardrail[]`    | 最初の ユーザー 入力に適用されるガードレール                                  |
| `outputGuardrails`          | `OutputGuardrail[]`   | 最終出力に適用されるガードレール                                              |
| `tracingDisabled`           | `boolean`             | OpenAI トレーシングを完全に無効化します                                       |
| `traceIncludeSensitiveData` | `boolean`             | スパンは送出しつつ、トレースから LLM/ツールの入力・出力を除外します           |
| `workflowName`              | `string`              | Traces ダッシュボードに表示され、関連する実行をグルーピングするのに役立ちます |
| `traceId` / `groupId`       | `string`              | SDK に生成させず、トレース ID またはグループ ID を手動で指定します            |
| `traceMetadata`             | `Record<string, any>` | すべてのスパンに添付する任意のメタデータ                                      |

## 会話 / チャットスレッド

`runner.run()`（または `run()` ユーティリティ）への各呼び出しは、アプリケーションレベルの会話における 1 つの **ターン** を表します。エンド ユーザー にどれだけの `RunResult` を見せるかは任意です。`finalOutput` のみの場合もあれば、生成されたすべてのアイテムを見せる場合もあります。

<Code lang="typescript" code={chatLoopExample} title="会話履歴を引き継ぐ例" />

インタラクティブ版は[チャットのサンプルコード](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts)を参照してください。

### サーバー管理の会話

OpenAI Responses API に会話履歴を保持させれば、毎ターンでローカルの全文書起こしを送信する必要がありません。長い会話や複数サービスの調整に便利です。詳細は[Conversation state guide](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)を参照してください。

OpenAI は、サーバーサイド状態を再利用する 2 つの方法を提供します:

#### 1. 会話全体に対する `conversationId`

[Conversations API](https://platform.openai.com/docs/api-reference/conversations/create) で一度会話を作成し、その ID を各ターンで再利用できます。SDK は新しく生成されたアイテムのみを自動的に含めます。

<Code
  lang="typescript"
  code={conversationIdExample}
  title="サーバー上の会話の再利用"
/>

#### 2. 直前のターンから続ける `previousResponseId`

最初から Responses API だけで始めたい場合は、前のレスポンスで返された ID を使って各リクエストを連結できます。これにより、会話リソースを作成せずにターン間でコンテキストを維持できます。

<Code
  lang="typescript"
  code={previousResponseIdExample}
  title="previousResponseId による連結"
/>

## 例外

SDK は捕捉可能な小さな集合のエラーを送出します:

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) – `maxTurns` に到達
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror) – モデルが不正な出力を生成（例: 形式不正な JSON、未知のツール）
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered) – ガードレール違反
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror) – ガードレールの実行失敗
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror) – 関数ツール の呼び出しが失敗
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror) – 構成または ユーザー 入力に基づいて送出されたエラー

いずれも基底の `AgentsError` クラスを拡張しており、現在の実行状態にアクセスするための `state` プロパティを提供する場合があります。

以下は `GuardrailExecutionError` を扱うコード例です:

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="ガードレール実行エラー"
/>

上の例を実行すると、次の出力が表示されます:

```
Guardrail execution failed: Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework guardrail tripped
```

---

## 次のステップ

- [モデル](/openai-agents-js/ja/guides/models) の設定方法を学ぶ
- エージェント に[ツール](/openai-agents-js/ja/guides/tools) を提供する
- 本番運用に向けて[ガードレール](/openai-agents-js/ja/guides/guardrails) や[トレーシング](/openai-agents-js/ja/guides/tracing) を追加する
