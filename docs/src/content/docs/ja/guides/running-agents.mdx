---
title: エージェントの実行
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';
import conversationIdExample from '../../../../../../examples/docs/running-agents/conversationId.ts?raw';
import previousResponseIdExample from '../../../../../../examples/docs/running-agents/previousResponseId.ts?raw';

エージェント はそれ自体では何もしません。`Runner` クラスまたは `run()` ユーティリティで実行します。

<Code lang="typescript" code={helloWorldExample} title="Simple run" />

カスタム runner が不要な場合は、シングルトンのデフォルト `Runner` インスタンスを実行する `run()` ユーティリティも使えます。

別の方法として、独自の runner インスタンスを作成できます。

<Code lang="typescript" code={helloWorldWithRunnerExample} title="Simple run" />

エージェント を実行すると、最終出力と実行全履歴を含む [result](/openai-agents-js/ja/guides/results) オブジェクトを受け取ります。

## エージェントループ

Runner の run メソッドを使うときは、開始するエージェント と入力を渡します。入力は文字列（ユーザー メッセージと見なされます）か、OpenAI Responses API のアイテムである入力アイテムのリストのいずれかです。

runner は次のループを実行します。

1. 現在の入力で現在のエージェント のモデルを呼び出す
2. LLM 応答を検査する
   - **Final output** → 返す
   - **Handoff** → 新しいエージェント に切り替え、蓄積された会話履歴を保持し、1 に戻る
   - **Tool calls** → ツールを実行し、その結果を会話に追加して、1 に戻る
3. `maxTurns` に到達したら [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) をスローする

<Aside type="note">
  LLM 出力が「final
  output」と見なされるルールは、望ましい型のテキスト出力を生成し、ツール呼び出しがない場合です。
</Aside>

### Runner のライフサイクル

アプリ起動時に `Runner` を作成し、リクエスト間で再利用します。インスタンスはモデルプロバイダーや トレーシング オプションなどのグローバル設定を保持します。まったく異なる構成が必要な場合のみ、別の `Runner` を作成します。簡単なスクリプトでは、内部でデフォルト runner を使う `run()` を呼び出すこともできます。

## Run の引数

`run()` メソッドへの入力は、開始時のエージェント、実行の入力、およびオプションのセットです。

入力は、文字列（ユーザー メッセージと見なされます）、[input items](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) のリスト、または [human-in-the-loop](/openai-agents-js/ja/guides/human-in-the-loop) エージェント を構築している場合は [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) オブジェクトのいずれかです。

追加のオプションは次のとおりです。

| Option                 | Default | Description                                                                                                                                          |
| ---------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| `stream`               | `false` | `true` の場合、呼び出しは `StreamedRunResult` を返し、モデルから到着したイベントを順次発行します                                                     |
| `context`              | –       | すべての tool / guardrail / handoff に転送されるコンテキストオブジェクト。詳細は [コンテキスト管理](/openai-agents-js/ja/guides/context) を参照      |
| `maxTurns`             | `10`    | セーフティリミット。到達時に [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) をスロー                  |
| `signal`               | –       | 取り消し用の `AbortSignal`                                                                                                                           |
| `session`              | –       | セッション 永続化の実装。詳しくは [セッション](/openai-agents-js/ja/guides/sessions) を参照                                                          |
| `sessionInputCallback` | –       | モデル呼び出し前に実行される、セッション履歴と新規入力のカスタムマージロジック。詳細は [セッション](/openai-agents-js/ja/guides/sessions) を参照     |
| `callModelInputFilter` | –       | モデル呼び出しの直前に、モデル入力（items と任意の instructions）を編集するフック。詳細は [Call model input filter](#call-model-input-filter) を参照 |
| `tracing`              | –       | 実行単位の トレーシング 構成の上書き（例: エクスポート用 API キー）                                                                                  |
| `conversationId`       | –       | サーバー 側の会話を再利用（OpenAI Responses API + Conversations API のみ）                                                                           |
| `previousResponseId`   | –       | 会話を作成せずに直前の Responses API 呼び出しから継続（OpenAI Responses API のみ）                                                                   |

## ストリーミング

ストリーミング を使うと、LLM 実行中のストリーミング イベントを追加で受け取れます。ストリームが開始されると、`StreamedRunResult` は実行に関する完全な情報（新しく生成されたすべての出力を含む）を保持します。`for await` ループでストリーミング イベントを反復処理できます。詳細は [ストリーミング](/openai-agents-js/ja/guides/streaming) を参照してください。

## Run の設定

独自の `Runner` インスタンスを作成する場合、runner を構成するために `RunConfig` オブジェクトを渡せます。

| Field                       | Type                     | Purpose                                                                                    |
| --------------------------- | ------------------------ | ------------------------------------------------------------------------------------------ |
| `model`                     | `string \| Model`        | 実行中の **すべて** のエージェント に特定のモデルを強制します                              |
| `modelProvider`             | `ModelProvider`          | モデル名を解決します。デフォルトは OpenAI プロバイダー                                     |
| `modelSettings`             | `ModelSettings`          | エージェント ごとの設定を上書きするグローバルなチューニング パラメーター                   |
| `handoffInputFilter`        | `HandoffInputFilter`     | ハンドオフ を行う際に入力アイテムを変更します（ハンドオフ 自体で既に定義されていない場合） |
| `inputGuardrails`           | `InputGuardrail[]`       | 最初の ユーザー 入力に適用される ガードレール                                              |
| `outputGuardrails`          | `OutputGuardrail[]`      | 最終 出力に適用される ガードレール                                                         |
| `tracingDisabled`           | `boolean`                | OpenAI トレーシング を完全に無効化                                                         |
| `traceIncludeSensitiveData` | `boolean`                | スパンは発行しつつ、トレースから LLM/ツールの入出力を除外                                  |
| `workflowName`              | `string`                 | Traces ダッシュボードに表示。関連する実行をグルーピングするのに役立ちます                  |
| `traceId` / `groupId`       | `string`                 | SDK に生成させず、トレース ID またはグループ ID を手動指定                                 |
| `traceMetadata`             | `Record<string, string>` | すべてのスパンに付与する任意のメタデータ                                                   |
| `tracing`                   | `TracingConfig`          | 実行単位の トレーシング 上書き（例: エクスポート用 API キー）                              |
| `sessionInputCallback`      | `SessionInputCallback`   | この runner 上のすべての実行に対するデフォルトの履歴マージ戦略                             |
| `callModelInputFilter`      | `CallModelInputFilter`   | 各モデル呼び出しの直前にモデル入力を編集するグローバルフック                               |

## 会話 / チャットスレッド

`runner.run()`（または `run()` ユーティリティ）への各呼び出しは、アプリケーション レベルの会話における 1 回の **ターン** を表します。エンド ユーザー にどの程度の `RunResult` を見せるかは自由です。`finalOutput` のみの場合もあれば、生成されたすべてのアイテムを表示する場合もあります。

<Code lang="typescript" code={chatLoopExample} title="会話履歴を引き継ぐ例" />

インタラクティブ版は [the chat example](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts) を参照してください。

### サーバー管理の会話

毎ターンごとにローカルの全文書を送信する代わりに、OpenAI Responses API に会話履歴を保持させることができます。これは長い会話や複数サービスを調整する際に有用です。詳細は [Conversation state guide](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses) を参照してください。

OpenAI は サーバー 側の状態を再利用する 2 つの方法を提供します。

#### 1. 会話全体に対する `conversationId`

[Conversations API](https://platform.openai.com/docs/api-reference/conversations/create) を使って一度会話を作成し、各ターンでその ID を再利用できます。SDK は新たに生成されたアイテムだけを自動的に含めます。

<Code
  lang="typescript"
  code={conversationIdExample}
  title="サーバー会話の再利用"
/>

#### 2. 直前のターンから続けるための `previousResponseId`

とにかく Responses API だけで始めたい場合、各リクエストを前回のレスポンスで返された ID を使って連結できます。これにより、完全な会話リソースを作成せずにターン間でコンテキストを維持できます。

<Code
  lang="typescript"
  code={previousResponseIdExample}
  title="previousResponseId によるチェイニング"
/>

## Call model input filter

`callModelInputFilter` を使って、モデルが呼び出される直前にモデル入力を編集します。このフックは現在のエージェント、context、（セッション履歴がある場合はそれも含む）結合済みの入力アイテムを受け取ります。機微情報のマスキング、古いメッセージの削除、追加の system guidance の挿入などのために、更新した `input` 配列と任意の `instructions` を返してください。

実行単位では `runner.run(..., { callModelInputFilter })` で、デフォルトでは `Runner` 構成（`RunConfig` の `callModelInputFilter`）で設定できます。

## 例外

SDK は捕捉可能な少数のエラーをスローします。

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) – `maxTurns` に到達
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror) – モデルが無効な出力を生成（例: 不正な JSON、未知のツール）
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered) – ガードレール 違反
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror) – ガードレール が完了できなかった
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror) – いずれかの 関数ツール 呼び出しが失敗
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror) – 構成または ユーザー 入力に基づくエラー

これらはすべて基底の `AgentsError` クラスを拡張しており、現在の実行状態にアクセスするための `state` プロパティを提供する場合があります。

以下は `GuardrailExecutionError` を処理するサンプルコードです。入力 ガードレール は最初の ユーザー 入力にのみ実行されるため、この例では元の入力と context で実行を再開します。また、保存した state を再利用して、モデルを再度呼び出すことなく出力 ガードレール を再試行する方法も示しています。

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="Guardrail execution error"
/>

入力と出力の再試行の違い:

- 入力 ガードレール は実行の最初の ユーザー 入力にのみ実行されるため、同じ入力 / context で新しい実行を開始して再試行する必要があります。保存した `state` を渡しても入力 ガードレール は再トリガーされません
- 出力 ガードレール はモデル応答の後に実行されるため、`GuardrailExecutionError` の保存済み `state` を再利用して、追加のモデル呼び出しなしで出力 ガードレール を再実行できます

上記の例を実行すると、次の出力が表示されます。

```
Guardrail execution failed (input): Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework input guardrail tripped on retry
Guardrail execution failed (output): Error: Output guardrail failed to complete: Error: Output guardrail crashed.
Output guardrail tripped after retry with saved state
```

---

## 次のステップ

- [モデル](/openai-agents-js/ja/guides/models) の構成方法を学ぶ
- エージェント に [ツール](/openai-agents-js/ja/guides/tools) を提供する
- 本番運用に向けて [ガードレール](/openai-agents-js/ja/guides/guardrails) や [トレーシング](/openai-agents-js/ja/guides/tracing) を追加する
