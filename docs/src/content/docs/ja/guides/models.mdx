---
title: モデル
description: Choose and configure language models for your agents
---

import { Code } from '@astrojs/starlight/components';
import modelCustomProviderExample from '../../../../../../examples/docs/models/customProviders.ts?raw';
import setDefaultOpenAIKeyExample from '../../../../../../examples/docs/config/setDefaultOpenAIKey.ts?raw';
import modelSettingsExample from '../../../../../../examples/docs/models/modelSettings.ts?raw';
import promptIdExample from '../../../../../../examples/basic/prompt-id.ts?raw';
import agentWithModelExample from '../../../../../../examples/docs/models/agentWithModel.ts?raw';
import runnerWithModelExample from '../../../../../../examples/docs/models/runnerWithModel.ts?raw';
import setTracingExportApiKeyExample from '../../../../../../examples/docs/config/setTracingExportApiKey.ts?raw';

最終的にあらゆる エージェント は LLM を呼び出します。SDK はモデルを 2 つの軽量なインターフェースの背後に抽象化します:

- [`Model`](/openai-agents-js/openai/agents/interfaces/model) – 特定の API に対して*1 回*のリクエストを行う方法を知っています
- [`ModelProvider`](/openai-agents-js/openai/agents/interfaces/modelprovider) – 人間が読めるモデルの**names**（例: `'gpt‑4o'`）を `Model` インスタンスに解決します

日常的な作業では、通常はモデルの**names** と、時折 `ModelSettings` のみを扱います。

<Code
  lang="typescript"
  code={agentWithModelExample}
  title="エージェントごとにモデルを指定"
/>

## デフォルトモデル

`Agent` を初期化するときにモデルを指定しない場合、デフォルトモデルが使用されます。現在のデフォルトは [`gpt-4.1`](https://platform.openai.com/docs/models/gpt-4.1) で、エージェントワークフローの予測可能性と低レイテンシのバランスに優れています。

[`gpt-5`](https://platform.openai.com/docs/models/gpt-5) などの他モデルに切り替えたい場合、エージェントを構成する方法は 2 つあります。

まず、カスタムモデルを設定していないすべての エージェント で特定のモデルを一貫して使用したい場合は、エージェントを実行する前に環境変数 `OPENAI_DEFAULT_MODEL` を設定します。

```bash
export OPENAI_DEFAULT_MODEL=gpt-5
node my-awesome-agent.js
```

次に、`Runner` インスタンスにデフォルトモデルを設定できます。エージェントでモデルを設定しない場合、この `Runner` のデフォルトモデルが使用されます。

<Code
  lang="typescript"
  code={runnerWithModelExample}
  title="Runner のデフォルトモデルを設定"
/>

### GPT-5 モデル

この方法で GPT-5 の推論モデル（[`gpt-5`](https://platform.openai.com/docs/models/gpt-5)、[`gpt-5-mini`](https://platform.openai.com/docs/models/gpt-5-mini)、または [`gpt-5-nano`](https://platform.openai.com/docs/models/gpt-5-nano)）を使用する場合、SDK は既定で妥当な `modelSettings` を適用します。具体的には、`reasoning.effort` と `verbosity` の両方を `"low"` に設定します。デフォルトモデルの推論負荷を調整するには、独自の `modelSettings` を渡します:

```ts
import { Agent } from '@openai/agents';

const myAgent = new Agent({
  name: 'My Agent',
  instructions: "You're a helpful agent.",
  modelSettings: {
    reasoning: { effort: 'minimal' },
    text: { verbosity: 'low' },
  },
  // If OPENAI_DEFAULT_MODEL=gpt-5 is set, passing only modelSettings works.
  // It's also fine to pass a GPT-5 model name explicitly:
  // model: 'gpt-5',
});
```

より低いレイテンシのために、[`gpt-5-mini`](https://platform.openai.com/docs/models/gpt-5-mini) または [`gpt-5-nano`](https://platform.openai.com/docs/models/gpt-5-nano) を `reasoning.effort="minimal"` で使用すると、既定設定より高速に応答が返ることが多いです。ただし、Responses API の一部の組み込みツール（ファイル検索や画像生成など）は `"minimal"` の推論負荷をサポートしていないため、この Agents SDK の既定値は `"low"` です。

### 非 GPT-5 モデル

カスタムの `modelSettings` なしで非 GPT-5 のモデル名を渡すと、SDK はあらゆるモデルと互換性のある汎用の `modelSettings` にフォールバックします。

---

## OpenAI プロバイダー

デフォルトの `ModelProvider` は OpenAI APIs を使って名前を解決します。2 つの異なるエンドポイントをサポートします:

| API              | 用途                                                                       | `setOpenAIAPI()` の呼び出し             |
| ---------------- | -------------------------------------------------------------------------- | --------------------------------------- |
| Chat Completions | 標準的なチャットと関数呼び出し                                             | `setOpenAIAPI('chat_completions')`      |
| Responses        | ツール呼び出しや柔軟な出力を備えた新しい ストリーミング ファースト生成 API | `setOpenAIAPI('responses')` _(default)_ |

### 認証

<Code
  lang="typescript"
  code={setDefaultOpenAIKeyExample}
  title="既定の OpenAI キーを設定"
/>

ネットワーク設定をカスタマイズする必要がある場合は、`setDefaultOpenAIClient(client)` を介して独自の `OpenAI` クライアントを接続することもできます。

---

## モデル設定 (ModelSettings)

`ModelSettings` は OpenAI の パラメーター を反映しつつ、プロバイダー非依存です。

| フィールド          | 型                                         | 注記                                                                           |
| ------------------- | ------------------------------------------ | ------------------------------------------------------------------------------ |
| `temperature`       | `number`                                   | 創造性と決定性のバランス                                                       |
| `topP`              | `number`                                   | Nucleus sampling                                                               |
| `frequencyPenalty`  | `number`                                   | 繰り返しトークンへのペナルティ                                                 |
| `presencePenalty`   | `number`                                   | 新しいトークンの促進                                                           |
| `toolChoice`        | `'auto' \| 'required' \| 'none' \| string` | [ツール使用の強制](/openai-agents-js/ja/guides/agents#forcing-tool-use) を参照 |
| `parallelToolCalls` | `boolean`                                  | サポートされる場合に並列の関数呼び出しを許可                                   |
| `truncation`        | `'auto' \| 'disabled'`                     | トークンの切り捨て戦略                                                         |
| `maxTokens`         | `number`                                   | 応答内の最大トークン数                                                         |
| `store`             | `boolean`                                  | 応答を永続化して取得 / RAG ワークフロー向けに保存                              |
| `reasoning.effort`  | `'minimal' \| 'low' \| 'medium' \| 'high'` | gpt-5 などの推論負荷                                                           |
| `text.verbosity`    | `'low' \| 'medium' \| 'high'`              | gpt-5 などのテキスト冗長度                                                     |

設定はどちらのレベルにも付与できます:

<Code lang="typescript" code={modelSettingsExample} title="モデル設定" />

`Runner` レベルの設定は、競合するエージェント単位の設定より優先されます。

---

## プロンプト

エージェント には `prompt` パラメーターを設定でき、これは エージェント の挙動を制御するために使用する サーバー 保存のプロンプト構成を示します。現在、このオプションは OpenAI の
[Responses API](https://platform.openai.com/docs/api-reference/responses) を使用する場合にのみサポートされています。

| フィールド  | 型       | 注記                                                                                                          |
| ----------- | -------- | ------------------------------------------------------------------------------------------------------------- |
| `promptId`  | `string` | プロンプトの一意の識別子                                                                                      |
| `version`   | `string` | 使用したいプロンプトのバージョン                                                                              |
| `variables` | `object` | プロンプトに代入する変数のキー/値の組。値は文字列、またはテキスト・画像・ファイルなどのコンテンツ入力型が可能 |

<Code
  lang="typescript"
  code={promptIdExample}
  title="プロンプト付きエージェント"
/>

tools や instructions などの追加の エージェント 構成は、保存済みプロンプトで設定している値を上書きします。

---

## カスタムモデルプロバイダー

独自のプロバイダーの実装は簡単です。`ModelProvider` と `Model` を実装し、そのプロバイダーを `Runner` コンストラクターに渡します:

<Code
  lang="typescript"
  code={modelCustomProviderExample}
  title="最小のカスタムプロバイダー"
/>

---

## トレーシングエクスポーター

OpenAI プロバイダーを使用する際、API キーを指定することで自動トレースエクスポートをオプトインできます:

<Code
  lang="typescript"
  code={setTracingExportApiKeyExample}
  title="トレーシングエクスポーター"
/>

これによりトレースが [OpenAI dashboard](https://platform.openai.com/traces) に送信され、ワークフローの完全な実行グラフを確認できます。

---

## 次のステップ

- [エージェントの実行](/openai-agents-js/ja/guides/running-agents) を参照
- [ツール](/openai-agents-js/ja/guides/tools) でモデルにスーパーパワーを付与
- 必要に応じて [ガードレール](/openai-agents-js/ja/guides/guardrails) や [トレーシング](/openai-agents-js/ja/guides/tracing) を追加
